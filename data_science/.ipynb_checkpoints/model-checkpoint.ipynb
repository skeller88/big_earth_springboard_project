{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# conda environments:\r\n",
      "#\r\n",
      "base                  *  /opt/conda\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!conda env list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/bin/python\n",
      "['/home/jovyan/work/Documents/big_earth_springboard_project/data_science', '/opt/conda/lib/python37.zip', '/opt/conda/lib/python3.7', '/opt/conda/lib/python3.7/lib-dynload', '', '/opt/conda/lib/python3.7/site-packages', '/opt/conda/lib/python3.7/site-packages/IPython/extensions', '/home/jovyan/.ipython']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "print(sys.path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import gc\n",
    "from joblib import dump, load\n",
    "import random\n",
    "import time\n",
    "from typing import List, Tuple\n",
    "\n",
    "from albumentations import (\n",
    "    Compose, Flip, Rotate\n",
    ")\n",
    "\n",
    "import dask\n",
    "import dask.array as da\n",
    "from google.cloud import storage\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_recall_fscore_support, precision_score, precision_recall_curve\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TensorBoard\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.metrics import Accuracy\n",
    "\n",
    "from data_engineering.dask_image_stats_collector import stats_for_numpy_images \n",
    "from data_science.augmented_image_sequence_from_npy import AugmentedImageSequenceFromNpy\n",
    "from data_science.keras.model_checkpoint_gcs import ModelCheckpointGCS\n",
    "from data_science.keras.cnn_models import basic_cnn_model, basic_cnn_model_with_best_practices\n",
    "from data_science.serialization_utils import numpy_to_json, sklearn_precision_recall_curve_to_dict\n",
    "from data_science.sklearn_batch_generator import SklearnBatchGenerator\n",
    "from data_science.train import get_model_and_metadata_from_gcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "n_classes = 1\n",
    "n_epochs = 100\n",
    "batch_size = 128\n",
    "\n",
    "early_stopping_patience = 6\n",
    "\n",
    "use_small_dataset = True\n",
    "use_random_small_dataset = False\n",
    "\n",
    "root = '/home/jovyan/work/data/big_earth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 57), started 0:08:56 ago. (Use '!kill 57' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-b46f792f93ede7db\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-b46f792f93ede7db\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 6006;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir \"gs://big_earth/model/logs/cloud_and_shadow_basic_cnn_2020_1_31\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "\n",
    "logger = logging.getLogger('papermill')\n",
    "handler = logging.StreamHandler(sys.stdout)\n",
    "logger.addHandler(handler)\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = '/app/.gcs/big-earth-252219-fb2e5c109f78.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root: /home/jovyan/work/data/big_earth\n"
     ]
    }
   ],
   "source": [
    "logger.info(f\"root: {root}\")\n",
    "pal = sns.color_palette()\n",
    "\n",
    "random_seed = 0\n",
    "random.seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "tf.random.set_seed(random_seed)\n",
    "\n",
    "project_name = \"cloud_and_shadow\"\n",
    "model_dir = os.path.join(root, \"model/models\")\n",
    "# blob prefix\n",
    "gcs_model_dir = \"model/models\"\n",
    "# tensorboard\n",
    "gcs_log_dir = \"gs://big_earth/model/logs\"\n",
    "\n",
    "for directory in [model_dir]:\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory, exist_ok=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n"
     ]
    }
   ],
   "source": [
    "logger.info('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcs_client = storage.Client()\n",
    "bucket = gcs_client.bucket(\"big_earth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 44)\n",
      "(1,)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "# np.array(json.loads(df['binarized_labels'].iloc[0])).shape\n",
    "\n",
    "def prepare_data(df):\n",
    "    df['has_cloud_and_shadow_target'] = df['has_cloud_and_shadow_target'].apply(lambda x: np.array(json.loads(x)))\n",
    "    df['binarized_labels'] = df['binarized_labels'].apply(lambda x: np.array(json.loads(x)))    \n",
    "    df['image_path'] = root + \"/npy_image_files/\" + df['image_prefix'] + \".npy\"\n",
    "    return df\n",
    "\n",
    "df = pd.read_csv(root + \"/metadata/metadata.csv\")\n",
    "df = prepare_data(df)\n",
    "logger.info(df['binarized_labels'].iloc[0].shape)\n",
    "logger.info(df['has_cloud_and_shadow_target'].iloc[0].shape)\n",
    "df = df.set_index('image_prefix', drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1907 253 240\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# len(pd.read_csv(root + '/google_automl_cloud_and_shadow_dataset.csv'))\n",
    "\n",
    "google_automl_dataset = pd.read_csv( '/app/data_science/google_automl_cloud_and_shadow_dataset_small.csv')\n",
    "google_automl_dataset['image_prefix'] = google_automl_dataset['gcs_uri'].str.split('/').apply(lambda x: x[-1].replace(\".png\", \"\"))\n",
    "google_automl_dataset = google_automl_dataset.set_index('image_prefix', drop=False)\n",
    "\n",
    "train = df.loc[google_automl_dataset[google_automl_dataset['set'] == 'TRAIN'].index]\n",
    "valid = df.loc[google_automl_dataset[google_automl_dataset['set'] == 'VALIDATION'].index]\n",
    "test = df.loc[google_automl_dataset[google_automl_dataset['set'] == 'TEST'].index]\n",
    "\n",
    "print(len(train), len(valid), len(test))\n",
    "print(len(train) + len(valid) + len(test) == len(google_automl_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(root + '/cloud_and_shadow_stats.csv'):\n",
    "    all_stats = pd.read_csv(root + '/cloud_and_shadow_stats.csv')\n",
    "else:\n",
    "    stat_list = []\n",
    "    npy_image_dir = root + \"/npy_image_files\"\n",
    "    npy_files = [npy_image_dir + \"/\" + file + \".npy\" for file in train['image_prefix'].values]\n",
    "    start = time.time()\n",
    "    stats = stats_for_numpy_images(npy_files,  use_test_data=False)\n",
    "    stats['data'] = 'all'\n",
    "    stat_list.append(stats)\n",
    "    \n",
    "    # get stats per class\n",
    "    no_cloud = train[train['has_cloud_and_shadow'] == 0]\n",
    "    cloud = train[train['has_cloud_and_shadow'] == 1]\n",
    "    print(len(no_cloud), len(cloud))\n",
    "\n",
    "    for name, data in [('no_cloud', no_cloud), ('cloud', cloud)]:\n",
    "        npy_files = [npy_image_dir + \"/\" + file + \".npy\" for file in data['image_prefix'].values]\n",
    "        stats = stats_for_numpy_images(npy_files,  use_test_data=False)\n",
    "        stats['data'] = name\n",
    "        stat_list.append(stats)    \n",
    "    \n",
    "    all_stats = pd.concat(stat_list)\n",
    "    all_stats['band'] = all_stats.index\n",
    "    all_stats = all_stats.reset_index()  \n",
    "    all_stats = all_stats.drop('index', axis=1)    \n",
    "    all_stats.to_csv(root + '/cloud_and_shadow_stats.csv', index=False)\n",
    "        \n",
    "    print(f'stats computed in {time.time() - start}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = all_stats[all_stats['data'] == 'all']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_histories(histories):\n",
    "    full_history = defaultdict(list)\n",
    "\n",
    "    for history in histories:\n",
    "        for key, value in history.history.items():\n",
    "            full_history[key].extend(value)\n",
    "    return full_history\n",
    "\n",
    "\n",
    "def graph_model_history(history):\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    t = f.suptitle('Basic CNN Performance', fontsize=12)\n",
    "    f.subplots_adjust(top=0.85, wspace=0.3)\n",
    "\n",
    "    max_epoch = len(history['val_loss']) + 1\n",
    "    epoch_list = list(range(1, max_epoch))\n",
    "    ax1.plot(epoch_list, history['accuracy'], label='Train Accuracy')\n",
    "    ax1.plot(epoch_list, history['val_accuracy'], label='Validation Accuracy')\n",
    "    ax1.set_xticks(np.arange(1, max_epoch, 5))\n",
    "    ax1.set_ylabel('Accuracy Value')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_title('Accuracy')\n",
    "    l1 = ax1.legend(loc=\"best\")\n",
    "\n",
    "    ax2.plot(epoch_list, history['loss'], label='Train Loss')\n",
    "    ax2.plot(epoch_list, history['val_loss'], label='Validation Loss')\n",
    "    ax2.set_xticks(np.arange(1, max_epoch, 5))\n",
    "    ax2.set_ylabel('Loss Value')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_title('Loss')\n",
    "    l2 = ax2.legend(loc=\"best\")\n",
    "\n",
    "\n",
    "def predict(model, model_path, x, batch_size, n_classes):\n",
    "    thresholds = np.array([0.5 for _ in range(n_classes)])\n",
    "    model.load_weights(model_path)\n",
    "\n",
    "    predict_generator = AugmentedImageSequenceFromNpy(x=x, y=None, batch_size=batch_size,\n",
    "                                                        augmentations=AUGMENTATIONS_TEST)\n",
    "    # Generators\n",
    "    pred_test_probs = model.predict_generator(predict_generator)\n",
    "    pred_test_labels = pd.DataFrame(pred_test_probs, columns=classes)\n",
    "    pred_test_labels = pred_test_labels.apply(lambda x: x > thresholds, axis=1)\n",
    "    # Convert boolean predictions to labels\n",
    "    pred_test_lables = pred_test_labels.apply(lambda row: ' '.join(row[row].index), axis=1)\n",
    "\n",
    "    del predict_generator\n",
    "    gc.collect()\n",
    "\n",
    "    return pred_test_labels\n",
    "\n",
    "AUGMENTATIONS_TRAIN = Compose([\n",
    "    Flip(p=0.5),\n",
    "    Rotate(limit=(0, 360), p=0.5)\n",
    "])\n",
    "\n",
    "AUGMENTATIONS_TEST = Compose([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1907, 1) (1,)\n",
      "(1907, 1) (1,)\n"
     ]
    }
   ],
   "source": [
    "x_train = train['image_path'].values\n",
    "x_valid = valid['image_path'].values\n",
    "x_test = test['image_path'].values\n",
    "\n",
    "target = 'has_cloud_and_shadow_target'\n",
    "y_train = np.stack(train[target].values)\n",
    "y_valid = np.stack(valid[target].values)\n",
    "y_test = np.stack(test[target].values)\n",
    "\n",
    "print(y_train.shape, y_train[0].shape)\n",
    "\n",
    "if use_small_dataset:\n",
    "    size = batch_size\n",
    "    n_epochs = 3\n",
    "    x_train = np.concatenate([x_train[:size], x_train[-size:]])\n",
    "    x_valid = np.concatenate([x_valid[:size], x_valid[-size:]])\n",
    "    x_test = np.concatenate([x_test[:size], x_test[-size:]])\n",
    "\n",
    "    y_train = np.concatenate([y_train[:size], y_train[-size:]])\n",
    "    y_valid = np.concatenate([y_valid[:size], y_valid[-size:]])\n",
    "    y_test = np.concatenate([y_test[:size], y_test[-size:]])\n",
    "elif use_random_small_dataset:\n",
    "    shape = (100, 1)\n",
    "    x_train = np.concatenate([np.ones(shape), np.zeros(shape)])\n",
    "    y_train = np.concatenate([np.ones(shape), np.zeros(shape)])\n",
    "\n",
    "    x_valid = np.concatenate([np.ones(shape), np.zeros(shape)])\n",
    "    y_valid = np.concatenate([np.ones(shape), np.zeros(shape)])\n",
    "\n",
    "    y_train = np.random.randint(0, 2, (len(train), 44))\n",
    "    y_valid = np.random.randint(0, 2, (len(valid), 44))\n",
    "    y_test = np.random.randint(0, 2, (len(test), 44))\n",
    "    y_test_labels = test['labels'].values\n",
    "\n",
    "print(y_train.shape, y_train[0].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 43200) (43200,) (128,) ()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/app/env/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.546875\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# sanity check the generator output\n",
    "train_batch_generator = SklearnBatchGenerator(x_train, y_train, batch_size, augmentations=None, band_stats=stats)\n",
    "valid_batch_generator = SklearnBatchGenerator(x_valid, y_valid, batch_size, augmentations=None, band_stats=stats)\n",
    "\n",
    "train_batch_generator.on_epoch_end()\n",
    "valid_batch_generator.on_epoch_end()\n",
    "\n",
    "clf = LogisticRegression()\n",
    "x, y = train_batch_generator[0]\n",
    "print(x.shape, x[0].shape, y.shape, y[0].shape)\n",
    "assert x.shape[-1] == 120 * 120 * 3\n",
    "clf.fit(x, y)\n",
    "\n",
    "x, y = valid_batch_generator[0]\n",
    "pred = clf.predict(x)\n",
    "print(accuracy_score(pred, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.04255583572926459 0.8784629281732327\n",
      "-0.055612034546092 0.9152328872912798\n",
      "-0.10637636081662913 0.85306616746429\n",
      "0.05590347030378144 1.0581742231027134\n",
      "0.009320551740954142 1.008796793941446\n"
     ]
    }
   ],
   "source": [
    "# check that the pixel values are different and reasonable\n",
    "num_outputs = 0\n",
    "for batch_x, batch_y in train_batch_generator.make_one_shot_iterator():\n",
    "    print(batch_x.mean(), batch_x.std())\n",
    "    num_outputs += 1\n",
    "    if num_outputs > 4:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/jovyan/work/data/big_earth/npy_image_files/S2A_MSIL2A_20170613T101031_57_5.npy'\n",
      " '/home/jovyan/work/data/big_earth/npy_image_files/S2B_MSIL2A_20170914T93030_56_82.npy'\n",
      " '/home/jovyan/work/data/big_earth/npy_image_files/S2B_MSIL2A_20171016T101009_47_86.npy'\n",
      " '/home/jovyan/work/data/big_earth/npy_image_files/S2B_MSIL2A_20180417T102019_59_50.npy'\n",
      " '/home/jovyan/work/data/big_earth/npy_image_files/S2A_MSIL2A_20180225T114351_6_43.npy']\n",
      "\n",
      "\n",
      "\n",
      "['/home/jovyan/work/data/big_earth/npy_image_files/S2A_MSIL2A_20180205T100211_64_19.npy'\n",
      " '/home/jovyan/work/data/big_earth/npy_image_files/S2B_MSIL2A_20170924T93021_20_59.npy'\n",
      " '/home/jovyan/work/data/big_earth/npy_image_files/S2A_MSIL2A_20170701T093031_64_73.npy'\n",
      " '/home/jovyan/work/data/big_earth/npy_image_files/S2B_MSIL2A_20180511T100029_26_44.npy'\n",
      " '/home/jovyan/work/data/big_earth/npy_image_files/S2A_MSIL2A_20171101T094131_44_70.npy']\n"
     ]
    }
   ],
   "source": [
    "# make sure shuffle works\n",
    "print(train_batch_generator.x[:5])\n",
    "print('\\n\\n')\n",
    "train_batch_generator.on_epoch_end()\n",
    "print(train_batch_generator.x[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_num 1 - 10.3475 sec - 0.6403162055335968\n",
      "epoch_num 2 - 13.5856 sec - 0.6047430830039525\n",
      "epoch_num 3 - 14.3071 sec - 0.6482213438735178\n",
      "epoch_num 4 - 15.1620 sec - 0.5849802371541502\n",
      "epoch_num 5 - 12.0106 sec - 0.6482213438735178\n",
      "epoch_num 6 - 14.7846 sec - 0.4782608695652174\n",
      "epoch_num 7 - 14.2541 sec - 0.6086956521739131\n",
      "epoch_num 8 - 17.1796 sec - 0.6363636363636364\n",
      "epoch_num 9 - 15.3449 sec - 0.6086956521739131\n",
      "Ending training due to no improvement\n"
     ]
    }
   ],
   "source": [
    "import joblib \n",
    "\n",
    "history = list()\n",
    "\n",
    "classes = np.array([0, 1])\n",
    "epochs_without_improvement = 0\n",
    "\n",
    "now = datetime.datetime.utcnow().strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "experiment_name = f\"sgd_classifier_default_2020_1_31\"\n",
    "gcs_model_dir = \"model/models\"\n",
    "model_path = os.path.join(model_dir, experiment_name + \".joblib\")\n",
    "model_gcs_path = os.path.join(gcs_model_dir, experiment_name + \".joblib\")\n",
    "model_metadata_path = os.path.join(model_dir, experiment_name + \"_metadata.json\")\n",
    "model_metadata_gcs_path = os.path.join(gcs_model_dir, experiment_name + \"_metadata.json\")\n",
    "\n",
    "model, model_base_metadata = get_model_and_metadata_from_gcs(bucket, model_dir, \"joblib\", joblib.load, gcs_model_dir, \n",
    "                                                             experiment_name)\n",
    "\n",
    "if model is not None:\n",
    "    print('Resuming training at epoch', model_base_metadata['epoch'])\n",
    "else:\n",
    "    model = SGDClassifier()\n",
    "    model_base_metadata = {\n",
    "        'data': 'train_valid_google_automl_cloud_and_shadow_dataset_small.csv',\n",
    "        'data_prep': 'normalization_augmentation',\n",
    "        'experiment_name': experiment_name,\n",
    "        'experiment_start_time': now,\n",
    "        'model': SGDClassifier.__name__,\n",
    "        'random_state': random_seed,\n",
    "        'epoch': 0\n",
    "    }\n",
    "        \n",
    "# Shuffle the data\n",
    "train_batch_generator.on_epoch_end()\n",
    "valid_batch_generator.on_epoch_end()\n",
    "train_start = time.time()\n",
    "best_model = None\n",
    "max_accuracy_valid = None\n",
    "for epoch in range(int(model_base_metadata['epoch']) + 1, n_epochs):\n",
    "    start = time.time()\n",
    "    for batch_x, batch_y in train_batch_generator.make_one_shot_iterator():\n",
    "        model.partial_fit(batch_x, batch_y, classes=classes)\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print(\"training completed in\", time.time() - start, \"seconds\")\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    actual_y_train, pred_y_train = train_batch_generator.get_predictions(model)\n",
    "    actual_y_valid, pred_y_valid = valid_batch_generator.get_predictions(model)\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print(\"prediction completed in\", time.time() - start, \"seconds\")\n",
    "\n",
    "    epoch_time = f\"{time.time() - start:.4f}\"\n",
    "    epoch_metrics = {\n",
    "        'accuracy_train': sklearn.metrics.accuracy_score(actual_y_train, pred_y_train),\n",
    "        'accuracy_valid': sklearn.metrics.accuracy_score(actual_y_valid, pred_y_valid),        \n",
    "        \"f1_score_train\": sklearn.metrics.f1_score(actual_y_train, pred_y_train),\n",
    "        \"f1_score_valid\": sklearn.metrics.f1_score(actual_y_valid, pred_y_valid),        \n",
    "    }\n",
    "    history.append(epoch_metrics)\n",
    "    \n",
    "    print(\"epoch_num\", epoch, \"-\", epoch_time, \"sec -\", epoch_metrics['accuracy_valid'])\n",
    "    \n",
    "    if max_accuracy_valid is None or epoch_metrics['accuracy_valid'] > max_accuracy_valid:\n",
    "        max_accuracy_valid = epoch_metrics['accuracy_valid']\n",
    "        dump(model, model_path)\n",
    "        with open(model_metadata_path, 'w+') as json_file:\n",
    "            model_base_metadata.update({\n",
    "                'epoch': str(epoch),\n",
    "                'confusion_matrix': numpy_to_json(confusion_matrix(actual_y_valid, pred_y_valid)),\n",
    "                'precision_recall_curve': sklearn_precision_recall_curve_to_dict(\n",
    "                    sklearn.metrics.precision_recall_curve(actual_y_valid, pred_y_valid)),\n",
    "                'history': history,\n",
    "                'train_time_elapsed': time.time() - train_start\n",
    "            })\n",
    "            json.dump(model_base_metadata, json_file)\n",
    "        \n",
    "        for filename, gcs_filename in [(model_path, model_gcs_path), (model_metadata_path, model_metadata_gcs_path)]:\n",
    "            blob = bucket.blob(gcs_filename)\n",
    "            blob.upload_from_filename(filename)\n",
    "            \n",
    "        epochs_without_improvement = 0\n",
    "    else:\n",
    "        epochs_without_improvement += 1\n",
    "        \n",
    "    if epochs_without_improvement == early_stopping_patience:\n",
    "        print(\"Ending training due to no improvement\")\n",
    "        break\n",
    "        \n",
    "    train_batch_generator.on_epoch_end()\n",
    "    valid_batch_generator.on_epoch_end()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'/home/jovyan/work/data/big_earth/npy_image_files/S2A_MSIL2A_20170701T093031_83_63.npy', shape=(), dtype=string) tf.Tensor([1], shape=(1,), dtype=uint8)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def gen(x,  y):\n",
    "    for x, y in zip(x, y):\n",
    "        yield (x, y)\n",
    "        \n",
    "dataset = tf.data.Dataset.from_generator(gen, \n",
    "                             output_types=(tf.string, tf.uint8),\n",
    "                             args=(x_train, y_train,)).shuffle(buffer_size=len(x_train)) \n",
    "\n",
    "for x, y in dataset.make_one_shot_iterator():\n",
    "    print(x, y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.04451697824482122 0.9332157774055616 -0.6573675908079565 9.579098303995938\n",
      "-0.2201340164894321 0.5947328838634741 -0.6573675908079565 8.412651602029957\n",
      "-0.18517725326129322 0.7722270897198501 -0.6573675908079565 6.6709594719397645\n",
      "-0.1393382670738429 0.748669886407471 -0.6573675908079565 9.09640780839832\n",
      "0.019630228841119195 1.0296057729288108 -0.6579388221636933 8.852492019498698\n",
      "(128, 120, 120, 3) [-0.46961505 -0.60481431 -0.58579698] (128, 1) [0]\n",
      "-0.06137150042801542 0.8586501858273038 -0.6573675908079565 7.964782363141132\n",
      "-0.007467874547742728 1.0290880509502704 -0.6573675908079565 9.239786878688264\n",
      "0.10251998133931417 1.1605415154960153 -0.6579388221636933 9.579098303995938\n",
      "-0.09494767175631735 0.8652106850091142 -0.6573675908079565 8.471235964574094\n",
      "-0.10837998842064708 0.7652672769156915 -0.6573675908079565 8.92560963303301\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "def get_image_dataset(x, y, augmentations, band_stats, batch_size, n_epochs):\n",
    "    def image_path_and_label(image_paths, labels):\n",
    "        for idx, image_path in enumerate(image_paths):\n",
    "            yield (image_path, labels[idx])\n",
    "\n",
    "    means = band_stats['mean'].values\n",
    "    stds = band_stats['std'].values\n",
    "    \n",
    "    def image_loader(image_path, label):\n",
    "        img = np.load(tf.get_static_value(image_path))\n",
    "        normalized_img = (img - means) / stds\n",
    "\n",
    "        if augmentations is not None:\n",
    "            return augmentations(normalized_img), label\n",
    "        else:\n",
    "            return normalized_img, label\n",
    "\n",
    "    def tf_image_loader(image_path, label):\n",
    "      return tf.py_function(func = image_loader,\n",
    "                    inp = (image_path, label),\n",
    "                    Tout = (tf.float64,    # (H,W,3) img\n",
    "                            tf.uint8))  # label\n",
    "\n",
    "\n",
    "    dataset = tf.data.Dataset.from_generator(image_path_and_label, \n",
    "                                 output_types=(tf.string, tf.uint8),\n",
    "                                 args=(x, y,)).shuffle(buffer_size=len(x)) \n",
    "    dataset = dataset.map(tf_image_loader, num_parallel_calls=8)\n",
    "\n",
    "    return dataset.prefetch(5).batch(batch_size).repeat(n_epochs)\n",
    "\n",
    "train_dataset = get_image_dataset(x_train, y_train, augmentations=None, band_stats=stats, batch_size=128, n_epochs=1)\n",
    "\n",
    "train_generator = AugmentedImageSequenceFromNpy(x=x_train, y=y_train, batch_size=batch_size,\n",
    "                                                augmentations=None, band_stats=stats)\n",
    "\n",
    "# imgs, labels = train_generator[0]\n",
    "# print(imgs.shape, imgs[0][0][0], labels.shape, labels[0])\n",
    "\n",
    "# num_outputs = 0\n",
    "# for batch_x, batch_y in train_generator.make_one_shot_iterator():\n",
    "#     print(batch_x.mean(), batch_x.std(), batch_x.min(), batch_x.max())\n",
    "#     num_outputs += 1\n",
    "#     if num_outputs > 4:\n",
    "#         break\n",
    "\n",
    "num_outputs = 0\n",
    "train_iter = train_dataset.make_one_shot_iterator()\n",
    "imgs, labels = train_iter.get_next()\n",
    "print(imgs.shape, imgs.numpy()[0][0][0], labels.shape, labels.numpy()[0])\n",
    "\n",
    "for batch_x, batch_y in train_dataset.make_one_shot_iterator():\n",
    "    batch_x = batch_x.numpy() \n",
    "    print(batch_x.mean(), batch_x.std(), batch_x.min(), batch_x.max())\n",
    "    num_outputs += 1\n",
    "    if num_outputs > 4:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = AugmentedImageSequenceFromNpy(x=x_train, y=y_train, batch_size=batch_size,\n",
    "                                                augmentations=None, band_stats=stats)\n",
    "\n",
    "start = time.time()\n",
    "for x, y in train_generator.make_one_shot_iterator():\n",
    "    continue\n",
    "print(f'AugmentedImageSequenceFromNpy finished in {time.time() - start}')\n",
    "\n",
    "start = time.time()\n",
    "train_dataset = get_image_dataset(x_train, y_train, augmentations=None, band_stats=stats, batch_size=batch_size)\n",
    "for x, y in train_dataset.make_one_shot_iterator():\n",
    "    continue\n",
    "print(f'Image dataset finished in {time.time() - start}')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image dataset finished in 6.941505670547485\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "train_dataset = get_image_dataset(x_train, y_train, augmentations=None, band_stats=stats, batch_size=batch_size)\n",
    "for x, y in train_dataset.make_one_shot_iterator():\n",
    "    continue\n",
    "print(f'Image dataset finished in {time.time() - start}')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary_crossentropy - random numbers 0.9841078217706439\n",
      "binary_crossentropy - cnn with initial weights - actual data 0.7664616\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7f5e11245fd0>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "model = basic_cnn_model((120, 120, 3), n_classes)\n",
    "y_actual, y_pred, y_pred_probs = train_batch_generator.get_predictions(model)\n",
    "\n",
    "print('binary_crossentropy - random numbers', \n",
    "      binary_crossentropy(np.random.randint(2, size=128), np.random.random_sample(128)).numpy())\n",
    "print('binary_crossentropy - cnn with initial weights - actual data', \n",
    "      binary_crossentropy(y_actual, np.ravel(y_pred_probs)).numpy())\n",
    "\n",
    "pd.DataFrame(y_pred_probs).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 1 steps\n",
      "Epoch 1/100\n",
      "1/1 [==============================] - 1s 950ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 288ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 00007: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Confirm that the model can overfit on a subset of the data\n",
    "def validate_can_overfit(model, train_generator)\n",
    "    n_epochs = 100\n",
    "    metrics = [Accuracy()]\n",
    "    loss = 'binary_crossentropy'\n",
    "    metric_to_monitor = 'accuracy'\n",
    "    callbacks = [EarlyStopping(monitor=metric_to_monitor, patience=early_stopping_patience, verbose=1)]\n",
    "\n",
    "    optimizer = Adam(lr=3e-4)\n",
    "    model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
    "\n",
    "    history = model.fit(train_generator,\n",
    "                        epochs=n_epochs,\n",
    "                        steps_per_epoch=len(train_generator),\n",
    "                        callbacks=callbacks,\n",
    "                        shuffle=True, verbose=1)\n",
    "\n",
    "    assert history.history['loss'][-1] == 0\n",
    "    assert history.history['accuracy'][-1] == 1\n",
    "    \n",
    "train_generator = AugmentedImageSequenceFromNpy(x=x_train[:10], y=y_train[:10], batch_size=batch_size, \n",
    "                                                augmentations=None, band_stats=stats)\n",
    "validate_can_overfit(model, train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def train_keras_model(*, bucket, model_dir, gcs_model_dir, gcs_log_dir, experiment_name, start_model,\n",
    "                     n_epochs=100):\n",
    "    model, model_base_metadata = get_model_and_metadata_from_gcs(bucket, model_dir, \"h5\", load_model, gcs_model_dir, experiment_name)\n",
    "\n",
    "    model_and_metadata_filepath = os.path.join(model_dir, experiment_name)\n",
    "    gcs_model_and_metadata_filepath = os.path.join(gcs_model_dir, experiment_name)\n",
    "    gcs_log_dir = os.path.join(gcs_log_dir, experiment_name)\n",
    "\n",
    "    if model is not None:\n",
    "        print('Resuming training at epoch', int(model_base_metadata['epoch']) + 1)\n",
    "    else:\n",
    "        now = datetime.datetime.utcnow().strftime(\"%Y-%m-%d %H:%M\")\n",
    "        model = start_model\n",
    "        model_base_metadata = {\n",
    "            'data': 'train_valid_google_automl_cloud_and_shadow_dataset_small.csv',\n",
    "            'data_prep': 'normalization_augmentation',\n",
    "            'experiment_name': experiment_name,\n",
    "            'experiment_start_time': now,\n",
    "            'model': 'keras_cnn',\n",
    "            'random_state': random_seed,\n",
    "            # so that initial_epoch is 0\n",
    "            'epoch': -1\n",
    "        }        \n",
    "\n",
    "    print(f'len(train): {len(x_train)}')\n",
    "    print(f'len(valid): {len(x_valid)}')\n",
    "\n",
    "    histories = []\n",
    "    metrics = ['accuracy']\n",
    "    loss = 'binary_crossentropy'\n",
    "    metric_to_monitor = 'val_accuracy'\n",
    "\n",
    "    optimizer = Adam()\n",
    "    model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
    "\n",
    "    verbosity = 0\n",
    "    # Generators\n",
    "    train_generator = AugmentedImageSequenceFromNpy(x=x_train, y=y_train, batch_size=batch_size,\n",
    "                                                    augmentations=None, band_stats=stats)\n",
    "\n",
    "    valid_generator = AugmentedImageSequenceFromNpy(x=x_valid, y=y_valid, batch_size=batch_size,\n",
    "                                                    augmentations=None, band_stats=stats)\n",
    "\n",
    "    callbacks = [\n",
    "#         EarlyStopping(monitor=metric_to_monitor, patience=early_stopping_patience, verbose=verbosity),\n",
    "#         ReduceLROnPlateau(monitor=metric_to_monitor, factor=0.5, patience=early_stopping_patience, min_lr=1e-6),\n",
    "        TensorBoard(gcs_log_dir, histogram_freq=1),\n",
    "        ModelCheckpointGCS(filepath=model_and_metadata_filepath, gcs_filepath=gcs_model_and_metadata_filepath, \n",
    "                           gcs_bucket=bucket, model_metadata=model_base_metadata, monitor=metric_to_monitor, \n",
    "                           verbose=verbosity)\n",
    "    ]\n",
    "\n",
    "    history = model.fit(train_generator, initial_epoch=int(model_base_metadata['epoch']) + 1,\n",
    "                                  epochs=n_epochs,\n",
    "                                  steps_per_epoch=len(train_generator),\n",
    "                                  callbacks=callbacks,\n",
    "                                  validation_data=valid_generator, validation_steps=len(valid_generator),\n",
    "                                  shuffle=True, verbose=1)\n",
    "\n",
    "    actual_y_train, pred_y_train, pred_y_train_probs = train_generator.get_predictions(model)\n",
    "    actual_y_valid, pred_y_valid, pred_y_valid_probs = valid_generator.get_predictions(model)\n",
    "\n",
    "    metadata_filepath = f\"{model_and_metadata_filepath}_metadata.json\"\n",
    "    with open(metadata_filepath, 'r') as json_file:\n",
    "        best_model_metadata = json.load(json_file)\n",
    "\n",
    "    best_model_metadata.update({\n",
    "        'accuracy_train': sklearn.metrics.accuracy_score(actual_y_train, pred_y_train),\n",
    "        'accuracy_valid': sklearn.metrics.accuracy_score(actual_y_valid, pred_y_valid),\n",
    "        'f1_score_train': sklearn.metrics.f1_score(actual_y_train, pred_y_train),\n",
    "        'f1_score_valid': sklearn.metrics.f1_score(actual_y_valid, pred_y_valid),\n",
    "        'confusion_matrix': numpy_to_json(sklearn.metrics.confusion_matrix(actual_y_valid, pred_y_valid)),\n",
    "        'precision_recall_curve': sklearn_precision_recall_curve_to_dict(\n",
    "            sklearn.metrics.precision_recall_curve(actual_y_valid, pred_y_valid)),\n",
    "    })\n",
    "\n",
    "    with open(metadata_filepath, 'w+') as json_file:\n",
    "        json.dump(best_model_metadata, json_file)\n",
    "\n",
    "    blob = bucket.blob(f\"{gcs_model_and_metadata_filepath}_metadata.json\")\n",
    "    blob.upload_from_filename(metadata_filepath)\n",
    "\n",
    "    # Attempt to avoid memory leaks\n",
    "    del train_generator\n",
    "    del valid_generator\n",
    "    gc.collect()\n",
    "    return history\n",
    "\n",
    "# if os.environ.get(\"SHOULD_PREDICT\", \"True\") == \"True\":\n",
    "#     pred_test_labels = predict(model=model, weight_dir=model_path, x=x_test, batch_size=batch_size, n_classes=n_classes)\n",
    "#     clf_report = classification_report(y_test_labels, pred_test_labels, target_names=classes)\n",
    "#     print(clf_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(train): 256\n",
      "len(valid): 256\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n",
      "Train for 2 steps, validate for 2 steps\n",
      "Epoch 1/3\n",
      "1/2 [==============>...............] - ETA: 4s - loss: 0.4389 - accuracy: 1.0000WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (2.222144). Check your callbacks.\n",
      "2/2 [==============================] - 30s 15s/step - loss: 47.7670 - accuracy: 0.5000 - val_loss: 7.8142 - val_accuracy: 0.5469\n",
      "Epoch 2/3\n",
      "2/2 [==============================] - 10s 5s/step - loss: 10.6520 - accuracy: 0.0469 - val_loss: 0.6800 - val_accuracy: 0.5469\n",
      "Epoch 3/3\n",
      "2/2 [==============================] - 11s 6s/step - loss: 0.7885 - accuracy: 0.5000 - val_loss: 0.6864 - val_accuracy: 0.5469\n",
      "Finished training for experiment cloud_and_shadow_basic_cnn_2020_1_31\n"
     ]
    }
   ],
   "source": [
    "experiment_name = f\"{project_name}_basic_cnn_2020_1_31\"\n",
    "history = train_keras_model(bucket=bucket, model_dir=model_dir, gcs_model_dir=gcs_model_dir, gcs_log_dir=gcs_log_dir, \n",
    "                  experiment_name=experiment_name, start_model=basic_cnn_model((120, 120, 3), n_classes=n_classes),\n",
    "                            n_epochs=3)\n",
    "logger.info(f\"Finished training for experiment {experiment_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f5e0485a828>"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading previously trained model.\n",
      "Resuming training at epoch 1\n",
      "len(train): 100\n",
      "len(valid): 100\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 1 steps, validate for 1 steps\n",
      "Epoch 2/3\n",
      "1/1 [==============================] - 20s 20s/step - loss: 1.4209 - accuracy: 0.0400 - val_loss: 5.7233 - val_accuracy: 0.0100\n",
      "Epoch 3/3\n",
      "WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (3.772809). Check your callbacks.\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.6108 - accuracy: 0.0300 - val_loss: 8.5210 - val_accuracy: 0.0000e+00\n",
      "Finished training for experiment cloud_and_shadow_basic_cnn_best_practices_2020_1_31\n",
      "Finished training for experiment cloud_and_shadow_basic_cnn_best_practices_2020_1_31\n"
     ]
    }
   ],
   "source": [
    "# experiment_name = f\"{project_name}_basic_cnn_best_practices_2020_1_31\"\n",
    "# train_keras_model(bucket=bucket, model_dir=model_dir, gcs_model_dir=gcs_model_dir, gcs_log_dir=gcs_log_dir, \n",
    "#                   experiment_name=experiment_name, start_model=basic_cnn_model_with_best_practices((120, 120, 3), n_classes=n_classes))\n",
    "# logger.info(f\"Finished training for experiment {experiment_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import classification_report\n",
    "\n",
    "# test_generator = AugmentedImageSequenceFromNpy(x=x_test, y=None, batch_size=batch_size,\n",
    "#                                                         augmentations=AUGMENTATIONS_TEST)\n",
    "# y_pred = model.predict(test_generator)\n",
    "# y_pred_binary = [0 if pred < .5 else 1 for pred in y_pred]\n",
    "# clf = classification_report(y_test, y_pred_binary,  target_names=['has_clouds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(pd.DataFrame(y_pred)[0].unique())\n",
    "# print(pd.DataFrame(y_pred_binary)[0].unique())\n",
    "# pd.DataFrame(y_pred)[0].unique()\n",
    "# pd.DataFrame(y_pred_binary)[0].unique()\n",
    "# full_histories = join_histories(histories)\n",
    "# graph_model_history(full_histories)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

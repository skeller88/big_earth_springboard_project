{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# conda environments:\r\n",
      "#\r\n",
      "base                  *  /opt/conda\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!conda env list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/bin/python\n",
      "['/home/jovyan/work/Documents/big_earth_springboard_project/data_science', '/opt/conda/lib/python37.zip', '/opt/conda/lib/python3.7', '/opt/conda/lib/python3.7/lib-dynload', '', '/opt/conda/lib/python3.7/site-packages', '/opt/conda/lib/python3.7/site-packages/IPython/extensions', '/home/jovyan/.ipython']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "print(sys.path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import gc\n",
    "from joblib import dump, load\n",
    "import random\n",
    "import time\n",
    "from typing import List, Tuple\n",
    "\n",
    "from albumentations import (\n",
    "    Compose, Flip, Rotate\n",
    ")\n",
    "\n",
    "import dask\n",
    "import dask.array as da\n",
    "from google.cloud import storage\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_recall_fscore_support, precision_score, precision_recall_curve\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TensorBoard\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.metrics import Accuracy\n",
    "\n",
    "from data_engineering.dask_image_stats_collector import stats_for_numpy_images \n",
    "from data_science.augmented_image_sequence_from_npy import AugmentedImageSequenceFromNpy\n",
    "from data_science.keras.model_checkpoint_gcs import ModelCheckpointGCS\n",
    "from data_science.keras.cnn_models import basic_cnn_model, basic_cnn_model_with_best_practices\n",
    "from data_science.serialization_utils import numpy_to_json, sklearn_precision_recall_curve_to_dict\n",
    "from data_science.sklearn_batch_generator import SklearnBatchGenerator\n",
    "from data_science.train import get_model_and_metadata_from_gcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "n_classes = 1\n",
    "n_epochs = 100\n",
    "batch_size = 128\n",
    "\n",
    "early_stopping_patience = 6\n",
    "\n",
    "use_small_dataset = True\n",
    "use_random_small_dataset = False\n",
    "\n",
    "root = '/home/jovyan/work/data/big_earth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 57), started 0:08:56 ago. (Use '!kill 57' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-b46f792f93ede7db\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-b46f792f93ede7db\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 6006;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir \"gs://big_earth/model/logs/cloud_and_shadow_basic_cnn_2020_1_31\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "\n",
    "logger = logging.getLogger('papermill')\n",
    "handler = logging.StreamHandler(sys.stdout)\n",
    "logger.addHandler(handler)\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = '/app/.gcs/big-earth-252219-fb2e5c109f78.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root: /home/jovyan/work/data/big_earth\n"
     ]
    }
   ],
   "source": [
    "logger.info(f\"root: {root}\")\n",
    "pal = sns.color_palette()\n",
    "\n",
    "random_seed = 0\n",
    "random.seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "tf.random.set_seed(random_seed)\n",
    "\n",
    "project_name = \"cloud_and_shadow\"\n",
    "model_dir = os.path.join(root, \"model/models\")\n",
    "# blob prefix\n",
    "gcs_model_dir = \"model/models\"\n",
    "# tensorboard\n",
    "gcs_log_dir = \"gs://big_earth/model/logs\"\n",
    "\n",
    "for directory in [model_dir]:\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory, exist_ok=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n"
     ]
    }
   ],
   "source": [
    "logger.info('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcs_client = storage.Client()\n",
    "bucket = gcs_client.bucket(\"big_earth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 44)\n",
      "(1,)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "# np.array(json.loads(df['binarized_labels'].iloc[0])).shape\n",
    "\n",
    "def prepare_data(df):\n",
    "    df['has_cloud_and_shadow_target'] = df['has_cloud_and_shadow_target'].apply(lambda x: np.array(json.loads(x)))\n",
    "    df['binarized_labels'] = df['binarized_labels'].apply(lambda x: np.array(json.loads(x)))    \n",
    "    df['image_path'] = root + \"/npy_image_files/\" + df['image_prefix'] + \".npy\"\n",
    "    return df\n",
    "\n",
    "df = pd.read_csv(root + \"/metadata/metadata.csv\")\n",
    "df = prepare_data(df)\n",
    "logger.info(df['binarized_labels'].iloc[0].shape)\n",
    "logger.info(df['has_cloud_and_shadow_target'].iloc[0].shape)\n",
    "df = df.set_index('image_prefix', drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1907 253 240\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# len(pd.read_csv(root + '/google_automl_cloud_and_shadow_dataset.csv'))\n",
    "\n",
    "google_automl_dataset = pd.read_csv( '/app/data_science/google_automl_cloud_and_shadow_dataset_small.csv')\n",
    "google_automl_dataset['image_prefix'] = google_automl_dataset['gcs_uri'].str.split('/').apply(lambda x: x[-1].replace(\".png\", \"\"))\n",
    "google_automl_dataset = google_automl_dataset.set_index('image_prefix', drop=False)\n",
    "\n",
    "train = df.loc[google_automl_dataset[google_automl_dataset['set'] == 'TRAIN'].index]\n",
    "valid = df.loc[google_automl_dataset[google_automl_dataset['set'] == 'VALIDATION'].index]\n",
    "test = df.loc[google_automl_dataset[google_automl_dataset['set'] == 'TEST'].index]\n",
    "\n",
    "print(len(train), len(valid), len(test))\n",
    "print(len(train) + len(valid) + len(test) == len(google_automl_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(root + '/cloud_and_shadow_stats.csv'):\n",
    "    all_stats = pd.read_csv(root + '/cloud_and_shadow_stats.csv')\n",
    "else:\n",
    "    stat_list = []\n",
    "    npy_image_dir = root + \"/npy_image_files\"\n",
    "    npy_files = [npy_image_dir + \"/\" + file + \".npy\" for file in train['image_prefix'].values]\n",
    "    start = time.time()\n",
    "    stats = stats_for_numpy_images(npy_files,  use_test_data=False)\n",
    "    stats['data'] = 'all'\n",
    "    stat_list.append(stats)\n",
    "    \n",
    "    # get stats per class\n",
    "    no_cloud = train[train['has_cloud_and_shadow'] == 0]\n",
    "    cloud = train[train['has_cloud_and_shadow'] == 1]\n",
    "    print(len(no_cloud), len(cloud))\n",
    "\n",
    "    for name, data in [('no_cloud', no_cloud), ('cloud', cloud)]:\n",
    "        npy_files = [npy_image_dir + \"/\" + file + \".npy\" for file in data['image_prefix'].values]\n",
    "        stats = stats_for_numpy_images(npy_files,  use_test_data=False)\n",
    "        stats['data'] = name\n",
    "        stat_list.append(stats)    \n",
    "    \n",
    "    all_stats = pd.concat(stat_list)\n",
    "    all_stats['band'] = all_stats.index\n",
    "    all_stats = all_stats.reset_index()  \n",
    "    all_stats = all_stats.drop('index', axis=1)    \n",
    "    all_stats.to_csv(root + '/cloud_and_shadow_stats.csv', index=False)\n",
    "        \n",
    "    print(f'stats computed in {time.time() - start}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = all_stats[all_stats['data'] == 'all']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_histories(histories):\n",
    "    full_history = defaultdict(list)\n",
    "\n",
    "    for history in histories:\n",
    "        for key, value in history.history.items():\n",
    "            full_history[key].extend(value)\n",
    "    return full_history\n",
    "\n",
    "\n",
    "def graph_model_history(history):\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    t = f.suptitle('Basic CNN Performance', fontsize=12)\n",
    "    f.subplots_adjust(top=0.85, wspace=0.3)\n",
    "\n",
    "    max_epoch = len(history['val_loss']) + 1\n",
    "    epoch_list = list(range(1, max_epoch))\n",
    "    ax1.plot(epoch_list, history['accuracy'], label='Train Accuracy')\n",
    "    ax1.plot(epoch_list, history['val_accuracy'], label='Validation Accuracy')\n",
    "    ax1.set_xticks(np.arange(1, max_epoch, 5))\n",
    "    ax1.set_ylabel('Accuracy Value')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_title('Accuracy')\n",
    "    l1 = ax1.legend(loc=\"best\")\n",
    "\n",
    "    ax2.plot(epoch_list, history['loss'], label='Train Loss')\n",
    "    ax2.plot(epoch_list, history['val_loss'], label='Validation Loss')\n",
    "    ax2.set_xticks(np.arange(1, max_epoch, 5))\n",
    "    ax2.set_ylabel('Loss Value')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_title('Loss')\n",
    "    l2 = ax2.legend(loc=\"best\")\n",
    "\n",
    "\n",
    "def predict(model, model_path, x, batch_size, n_classes):\n",
    "    thresholds = np.array([0.5 for _ in range(n_classes)])\n",
    "    model.load_weights(model_path)\n",
    "\n",
    "    predict_generator = AugmentedImageSequenceFromNpy(x=x, y=None, batch_size=batch_size,\n",
    "                                                        augmentations=AUGMENTATIONS_TEST)\n",
    "    # Generators\n",
    "    pred_test_probs = model.predict_generator(predict_generator)\n",
    "    pred_test_labels = pd.DataFrame(pred_test_probs, columns=classes)\n",
    "    pred_test_labels = pred_test_labels.apply(lambda x: x > thresholds, axis=1)\n",
    "    # Convert boolean predictions to labels\n",
    "    pred_test_lables = pred_test_labels.apply(lambda row: ' '.join(row[row].index), axis=1)\n",
    "\n",
    "    del predict_generator\n",
    "    gc.collect()\n",
    "\n",
    "    return pred_test_labels\n",
    "\n",
    "AUGMENTATIONS_TRAIN = Compose([\n",
    "    Flip(p=0.5),\n",
    "    Rotate(limit=(0, 360), p=0.5)\n",
    "])\n",
    "\n",
    "AUGMENTATIONS_TEST = Compose([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1907, 1) (1,)\n",
      "(256, 1) (1,)\n"
     ]
    }
   ],
   "source": [
    "x_train = train['image_path'].values\n",
    "x_valid = valid['image_path'].values\n",
    "x_test = test['image_path'].values\n",
    "\n",
    "target = 'has_cloud_and_shadow_target'\n",
    "y_train = np.stack(train[target].values)\n",
    "y_valid = np.stack(valid[target].values)\n",
    "y_test = np.stack(test[target].values)\n",
    "\n",
    "print(y_train.shape, y_train[0].shape)\n",
    "\n",
    "if use_small_dataset:\n",
    "    size = batch_size\n",
    "    n_epochs = 3\n",
    "    x_train = np.concatenate([x_train[:size], x_train[-size:]])\n",
    "    x_valid = np.concatenate([x_valid[:size], x_valid[-size:]])\n",
    "    x_test = np.concatenate([x_test[:size], x_test[-size:]])\n",
    "\n",
    "    y_train = np.concatenate([y_train[:size], y_train[-size:]])\n",
    "    y_valid = np.concatenate([y_valid[:size], y_valid[-size:]])\n",
    "    y_test = np.concatenate([y_test[:size], y_test[-size:]])\n",
    "elif use_random_small_dataset:\n",
    "    shape = (100, 1)\n",
    "    x_train = np.concatenate([np.ones(shape), np.zeros(shape)])\n",
    "    y_train = np.concatenate([np.ones(shape), np.zeros(shape)])\n",
    "\n",
    "    x_valid = np.concatenate([np.ones(shape), np.zeros(shape)])\n",
    "    y_valid = np.concatenate([np.ones(shape), np.zeros(shape)])\n",
    "\n",
    "    y_train = np.random.randint(0, 2, (len(train), 44))\n",
    "    y_valid = np.random.randint(0, 2, (len(valid), 44))\n",
    "    y_test = np.random.randint(0, 2, (len(test), 44))\n",
    "    y_test_labels = test['labels'].values\n",
    "\n",
    "print(y_train.shape, y_train[0].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class SklearnBatchGenerator:\n",
    "    def __init__(self, x: np.array, y: np.array, batch_size, augmentations, band_stats, has_verbose_logging=False, \n",
    "                 should_test_time_augment=False):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.base_index = [idx for idx in range(len(x))]\n",
    "        self.batch_size = batch_size\n",
    "        self.augmentations = augmentations\n",
    "        self.has_verbose_logging = has_verbose_logging\n",
    "        self.means = band_stats['mean'].values\n",
    "        self.stds = band_stats['std'].values\n",
    "        self.should_test_time_augment = should_test_time_augment\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.x) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, batch_num):\n",
    "        img_names= self.x[batch_num * self.batch_size:(batch_num + 1) * self.batch_size]\n",
    "\n",
    "        if self.y is not None:\n",
    "            batch_y = np.ravel(self.y[batch_num * self.batch_size:(batch_num + 1) * self.batch_size])\n",
    "\n",
    "            start = time.time()\n",
    "            batch_x = self.batch_loader(img_names, self.augmentations is not None)\n",
    "\n",
    "            if batch_num == 0 and self.has_verbose_logging:\n",
    "                print('fetched batch_num', batch_num, 'in', time.time() - start, 'seconds')\n",
    "\n",
    "            return batch_x, batch_y\n",
    "        # test (inference only)\n",
    "        else:\n",
    "            return self.batch_loader(img_names, self.should_test_time_augment)\n",
    "\n",
    "    def make_one_shot_iterator(self):\n",
    "        for batch_num in range(len(self)):\n",
    "            batch_x, batch_y = self[batch_num]\n",
    "            yield batch_x, batch_y\n",
    "\n",
    "    def batch_loader(self, image_paths, should_augment) -> np.array:\n",
    "        imgs = np.array([np.load(image_path) for image_path in image_paths])\n",
    "        normalized_imgs = (imgs - self.means) / self.stds\n",
    "        \n",
    "        if should_augment:\n",
    "            return np.stack([self.augmentations(image=x)[\"image\"].flatten() for x in normalized_imgs], axis=0)\n",
    "        return np.array([x.flatten() for x in normalized_imgs])\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        # Can't figure out how to pass in the epoch variable\n",
    "        #         print_with_stdout(f\"epoch {epoch}, logs {logs}\")\n",
    "        #         if logs is not None:\n",
    "        #             print_with_stdout(f\"finished epoch {epoch} with accuracy {logs['acc']} and val_loss {logs['val_loss']}\")\n",
    "        #         else:\n",
    "        #             print_with_stdout(f\"finished epoch {epoch}\")\n",
    "        # https://stackoverflow.com/questions/29576430/shuffle-dataframe-rows\n",
    "        shuffled_index = self.base_index.copy()\n",
    "        random.shuffle(shuffled_index)\n",
    "        self.x = self.x[shuffled_index]\n",
    "\n",
    "        if self.y is not None:\n",
    "            self.y = self.y[shuffled_index]\n",
    "\n",
    "    def get_predictions(self, model):\n",
    "        pred_y_batches = []\n",
    "        actual_y_batches = []\n",
    "        for batch_x, batch_y in self.make_one_shot_iterator():\n",
    "            pred_y_batches.append(model.predict(batch_x))\n",
    "            actual_y_batches.append(batch_y)\n",
    "\n",
    "        pred_y = []\n",
    "        for pred_y_batch in pred_y_batches:\n",
    "            for pred in pred_y_batch:\n",
    "                pred_y.append(pred)\n",
    "\n",
    "        actual_y = []\n",
    "        for actual_y_batch in actual_y_batches:\n",
    "            for actual in actual_y_batch:\n",
    "                actual_y.append(actual)\n",
    "\n",
    "        return actual_y, pred_y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 43200) (43200,) (128,) ()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/app/env/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.546875\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# sanity check the generator output\n",
    "train_batch_generator = SklearnBatchGenerator(x_train, y_train, batch_size, augmentations=None, band_stats=stats)\n",
    "valid_batch_generator = SklearnBatchGenerator(x_valid, y_valid, batch_size, augmentations=None, band_stats=stats)\n",
    "\n",
    "train_batch_generator.on_epoch_end()\n",
    "valid_batch_generator.on_epoch_end()\n",
    "\n",
    "clf = LogisticRegression()\n",
    "x, y = train_batch_generator[0]\n",
    "print(x.shape, x[0].shape, y.shape, y[0].shape)\n",
    "assert x.shape[-1] == 120 * 120 * 3\n",
    "clf.fit(x, y)\n",
    "\n",
    "x, y = valid_batch_generator[0]\n",
    "pred = clf.predict(x)\n",
    "print(accuracy_score(pred, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.04255583572926459 0.8784629281732327\n",
      "-0.055612034546092 0.9152328872912798\n",
      "-0.10637636081662913 0.85306616746429\n",
      "0.05590347030378144 1.0581742231027134\n",
      "0.009320551740954142 1.008796793941446\n"
     ]
    }
   ],
   "source": [
    "# check that the pixel values are different and reasonable\n",
    "num_outputs = 0\n",
    "for batch_x, batch_y in train_batch_generator.make_one_shot_iterator():\n",
    "    print(batch_x.mean(), batch_x.std())\n",
    "    num_outputs += 1\n",
    "    if num_outputs > 4:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/jovyan/work/data/big_earth/npy_image_files/S2A_MSIL2A_20170613T101031_57_5.npy'\n",
      " '/home/jovyan/work/data/big_earth/npy_image_files/S2B_MSIL2A_20170914T93030_56_82.npy'\n",
      " '/home/jovyan/work/data/big_earth/npy_image_files/S2B_MSIL2A_20171016T101009_47_86.npy'\n",
      " '/home/jovyan/work/data/big_earth/npy_image_files/S2B_MSIL2A_20180417T102019_59_50.npy'\n",
      " '/home/jovyan/work/data/big_earth/npy_image_files/S2A_MSIL2A_20180225T114351_6_43.npy']\n",
      "\n",
      "\n",
      "\n",
      "['/home/jovyan/work/data/big_earth/npy_image_files/S2A_MSIL2A_20180205T100211_64_19.npy'\n",
      " '/home/jovyan/work/data/big_earth/npy_image_files/S2B_MSIL2A_20170924T93021_20_59.npy'\n",
      " '/home/jovyan/work/data/big_earth/npy_image_files/S2A_MSIL2A_20170701T093031_64_73.npy'\n",
      " '/home/jovyan/work/data/big_earth/npy_image_files/S2B_MSIL2A_20180511T100029_26_44.npy'\n",
      " '/home/jovyan/work/data/big_earth/npy_image_files/S2A_MSIL2A_20171101T094131_44_70.npy']\n"
     ]
    }
   ],
   "source": [
    "# make sure shuffle works\n",
    "print(train_batch_generator.x[:5])\n",
    "print('\\n\\n')\n",
    "train_batch_generator.on_epoch_end()\n",
    "print(train_batch_generator.x[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_num 1 - 10.3475 sec - 0.6403162055335968\n",
      "epoch_num 2 - 13.5856 sec - 0.6047430830039525\n",
      "epoch_num 3 - 14.3071 sec - 0.6482213438735178\n",
      "epoch_num 4 - 15.1620 sec - 0.5849802371541502\n",
      "epoch_num 5 - 12.0106 sec - 0.6482213438735178\n",
      "epoch_num 6 - 14.7846 sec - 0.4782608695652174\n",
      "epoch_num 7 - 14.2541 sec - 0.6086956521739131\n",
      "epoch_num 8 - 17.1796 sec - 0.6363636363636364\n",
      "epoch_num 9 - 15.3449 sec - 0.6086956521739131\n",
      "Ending training due to no improvement\n"
     ]
    }
   ],
   "source": [
    "import joblib \n",
    "\n",
    "history = list()\n",
    "\n",
    "classes = np.array([0, 1])\n",
    "epochs_without_improvement = 0\n",
    "\n",
    "now = datetime.datetime.utcnow().strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "experiment_name = f\"sgd_classifier_default_2020_1_31\"\n",
    "gcs_model_dir = \"model/models\"\n",
    "model_path = os.path.join(model_dir, experiment_name + \".joblib\")\n",
    "model_gcs_path = os.path.join(gcs_model_dir, experiment_name + \".joblib\")\n",
    "model_metadata_path = os.path.join(model_dir, experiment_name + \"_metadata.json\")\n",
    "model_metadata_gcs_path = os.path.join(gcs_model_dir, experiment_name + \"_metadata.json\")\n",
    "\n",
    "model, model_base_metadata = get_model_and_metadata_from_gcs(bucket, model_dir, \"joblib\", joblib.load, gcs_model_dir, \n",
    "                                                             experiment_name)\n",
    "\n",
    "if model is not None:\n",
    "    print('Resuming training at epoch', model_base_metadata['epoch'])\n",
    "else:\n",
    "    model = SGDClassifier()\n",
    "    model_base_metadata = {\n",
    "        'data': 'train_valid_google_automl_cloud_and_shadow_dataset_small.csv',\n",
    "        'data_prep': 'normalization_augmentation',\n",
    "        'experiment_name': experiment_name,\n",
    "        'experiment_start_time': now,\n",
    "        'model': SGDClassifier.__name__,\n",
    "        'random_state': random_seed,\n",
    "        'epoch': 0\n",
    "    }\n",
    "        \n",
    "# Shuffle the data\n",
    "train_batch_generator.on_epoch_end()\n",
    "valid_batch_generator.on_epoch_end()\n",
    "train_start = time.time()\n",
    "best_model = None\n",
    "max_accuracy_valid = None\n",
    "for epoch in range(int(model_base_metadata['epoch']) + 1, n_epochs):\n",
    "    start = time.time()\n",
    "    for batch_x, batch_y in train_batch_generator.make_one_shot_iterator():\n",
    "        model.partial_fit(batch_x, batch_y, classes=classes)\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print(\"training completed in\", time.time() - start, \"seconds\")\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    actual_y_train, pred_y_train = train_batch_generator.get_predictions(model)\n",
    "    actual_y_valid, pred_y_valid = valid_batch_generator.get_predictions(model)\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print(\"prediction completed in\", time.time() - start, \"seconds\")\n",
    "\n",
    "    epoch_time = f\"{time.time() - start:.4f}\"\n",
    "    epoch_metrics = {\n",
    "        'accuracy_train': sklearn.metrics.accuracy_score(actual_y_train, pred_y_train),\n",
    "        'accuracy_valid': sklearn.metrics.accuracy_score(actual_y_valid, pred_y_valid),        \n",
    "        \"f1_score_train\": sklearn.metrics.f1_score(actual_y_train, pred_y_train),\n",
    "        \"f1_score_valid\": sklearn.metrics.f1_score(actual_y_valid, pred_y_valid),        \n",
    "    }\n",
    "    history.append(epoch_metrics)\n",
    "    \n",
    "    print(\"epoch_num\", epoch, \"-\", epoch_time, \"sec -\", epoch_metrics['accuracy_valid'])\n",
    "    \n",
    "    if max_accuracy_valid is None or epoch_metrics['accuracy_valid'] > max_accuracy_valid:\n",
    "        max_accuracy_valid = epoch_metrics['accuracy_valid']\n",
    "        dump(model, model_path)\n",
    "        with open(model_metadata_path, 'w+') as json_file:\n",
    "            model_base_metadata.update({\n",
    "                'epoch': str(epoch),\n",
    "                'confusion_matrix': numpy_to_json(confusion_matrix(actual_y_valid, pred_y_valid)),\n",
    "                'precision_recall_curve': sklearn_precision_recall_curve_to_dict(\n",
    "                    sklearn.metrics.precision_recall_curve(actual_y_valid, pred_y_valid)),\n",
    "                'history': history,\n",
    "                'train_time_elapsed': time.time() - train_start\n",
    "            })\n",
    "            json.dump(model_base_metadata, json_file)\n",
    "        \n",
    "        for filename, gcs_filename in [(model_path, model_gcs_path), (model_metadata_path, model_metadata_gcs_path)]:\n",
    "            blob = bucket.blob(gcs_filename)\n",
    "            blob.upload_from_filename(filename)\n",
    "            \n",
    "        epochs_without_improvement = 0\n",
    "    else:\n",
    "        epochs_without_improvement += 1\n",
    "        \n",
    "    if epochs_without_improvement == early_stopping_patience:\n",
    "        print(\"Ending training due to no improvement\")\n",
    "        break\n",
    "        \n",
    "    train_batch_generator.on_epoch_end()\n",
    "    valid_batch_generator.on_epoch_end()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def image_path_and_label(image_paths, labels):\n",
    "    for idx, image_path in enumerate(image_paths):\n",
    "        yield (image_path, labels[idx])\n",
    "        \n",
    "dataset = tf.data.Dataset.from_generator(image_path_and_label, \n",
    "                                         output_types=(tf.string, tf.uint8),\n",
    "                                         args=(x_train, y_train,)) \n",
    "\n",
    "\n",
    "augmentations = None\n",
    "means = stats['mean'].values\n",
    "stds = stats['std'].values\n",
    "\n",
    "def image_loader(image_path, label):\n",
    "    img = np.load(tf.get_static_value(image_path))\n",
    "    normalized_img = (img - means) / stds\n",
    "\n",
    "    if augmentations is not None:\n",
    "        return augmentations(normalized_img), label\n",
    "    else:\n",
    "        return normalized_img, label\n",
    "\n",
    "# def simple(image_path, label):\n",
    "#     return (np.random.rand(120, 120, 3), [0])\n",
    "    \n",
    "def tf_image_loader(image_path, label):\n",
    "  return tf.py_function(func = image_loader,\n",
    "                inp = (image_path, label),\n",
    "                Tout = (tf.float64,    # (H,W,3) img\n",
    "                        tf.uint8))  # label\n",
    "\n",
    "dataset = dataset.map(tf_image_loader, num_parallel_calls=8)\n",
    "\n",
    "dataset = dataset.batch(64)\n",
    "iter = dataset.make_one_shot_iterator()\n",
    "imgs, labels = iter.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/work/data/big_earth/npy_image_files/S2B_MSIL2A_20180421T100031_7_89.npy [0] None           mean          std  min    max data   band  index\n",
      "0  1037.286040  1904.295943    0  18946  all    red      0\n",
      "1  1151.790453  1750.604182    0  17921  all   blue      1\n",
      "2  1104.914808  1826.425950    0  17064  all  green      2\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Attempt to convert a value (None) with an unsupported type (<class 'NoneType'>) to a Tensor.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-270-b44d759a141c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_batch_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImageDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_paths\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maugmentations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mband_stats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_batch_generator\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-269-cb0a8b03b1d4>\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, image_paths, y, augmentations, band_stats)\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0moutput_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m120\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m120\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_paths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maugmentations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mband_stats\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         )\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/app/env/lib/python3.6/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mfrom_generator\u001b[0;34m(generator, output_types, output_shapes, args)\u001b[0m\n\u001b[1;32m    542\u001b[0m       \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 544\u001b[0;31m       \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_n_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"args\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    545\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m     \u001b[0mflattened_types\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/app/env/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_n_to_tensor\u001b[0;34m(values, dtype, name, preferred_dtype)\u001b[0m\n\u001b[1;32m   1395\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1396\u001b[0m       \u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1397\u001b[0;31m       as_ref=False)\n\u001b[0m\u001b[1;32m   1398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/app/env/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36minternal_convert_n_to_tensor\u001b[0;34m(values, dtype, name, as_ref, preferred_dtype, ctx)\u001b[0m\n\u001b[1;32m   1363\u001b[0m             \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m             \u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m             ctx=ctx))\n\u001b[0m\u001b[1;32m   1366\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/app/env/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36minternal_convert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, ctx, accept_composite_tensors)\u001b[0m\n\u001b[1;32m   1294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1295\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1296\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1298\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/app/env/lib/python3.6/site-packages/tensorflow_core/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    284\u001b[0m                                          as_ref=False):\n\u001b[1;32m    285\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/app/env/lib/python3.6/site-packages/tensorflow_core/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    225\u001b[0m   \"\"\"\n\u001b[1;32m    226\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0;32m--> 227\u001b[0;31m                         allow_broadcast=True)\n\u001b[0m\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/app/env/lib/python3.6/site-packages/tensorflow_core/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    233\u001b[0m   \u001b[0mctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m     \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/app/env/lib/python3.6/site-packages/tensorflow_core/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m     94\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Attempt to convert a value (None) with an unsupported type (<class 'NoneType'>) to a Tensor."
     ]
    }
   ],
   "source": [
    "train_batch_generator = ImageDataset(image_paths=x_train, y=y_train, augmentations=None, band_stats=stats)\n",
    "\n",
    "x, y = train_batch_generator[0]\n",
    "print(x.shape, y.shape, y[0])\n",
    "\n",
    "# check that the pixel values are different and reasonable\n",
    "num_outputs = 0\n",
    "for batch_x, batch_y in train_batch_generator.make_one_shot_iterator():\n",
    "    print(batch_x.mean(), batch_x.std(), batch_x.min(), batch_x.max())\n",
    "    num_outputs += 1\n",
    "    if num_outputs > 4:\n",
    "        break\n",
    "        \n",
    "# make sure shuffle works\n",
    "print('\\n')\n",
    "print(train_batch_generator.x[:5])\n",
    "print('\\n')\n",
    "train_batch_generator.on_epoch_end()\n",
    "print(train_batch_generator.x[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary_crossentropy - random numbers 0.9841078217706439\n",
      "binary_crossentropy - cnn with initial weights - actual data 0.7664616\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7f5e11245fd0>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "model = basic_cnn_model((120, 120, 3), n_classes)\n",
    "y_actual, y_pred, y_pred_probs = train_batch_generator.get_predictions(model)\n",
    "\n",
    "print('binary_crossentropy - random numbers', \n",
    "      binary_crossentropy(np.random.randint(2, size=128), np.random.random_sample(128)).numpy())\n",
    "print('binary_crossentropy - cnn with initial weights - actual data', \n",
    "      binary_crossentropy(y_actual, np.ravel(y_pred_probs)).numpy())\n",
    "\n",
    "pd.DataFrame(y_pred_probs).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 1 steps\n",
      "Epoch 1/100\n",
      "1/1 [==============================] - 1s 950ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 288ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 00007: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Confirm that the model can overfit on a subset of the data\n",
    "def validate_can_overfit(model, train_generator)\n",
    "    n_epochs = 100\n",
    "    metrics = [Accuracy()]\n",
    "    loss = 'binary_crossentropy'\n",
    "    metric_to_monitor = 'accuracy'\n",
    "    callbacks = [EarlyStopping(monitor=metric_to_monitor, patience=early_stopping_patience, verbose=1)]\n",
    "\n",
    "    optimizer = Adam(lr=3e-4)\n",
    "    model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
    "\n",
    "    history = model.fit(train_generator,\n",
    "                        epochs=n_epochs,\n",
    "                        steps_per_epoch=len(train_generator),\n",
    "                        callbacks=callbacks,\n",
    "                        shuffle=True, verbose=1)\n",
    "\n",
    "    assert history.history['loss'][-1] == 0\n",
    "    assert history.history['accuracy'][-1] == 1\n",
    "    \n",
    "train_generator = AugmentedImageSequenceFromNpy(x=x_train[:10], y=y_train[:10], batch_size=batch_size, \n",
    "                                                augmentations=None, band_stats=stats)\n",
    "validate_can_overfit(model, train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def train_keras_model(*, bucket, model_dir, gcs_model_dir, gcs_log_dir, experiment_name, start_model,\n",
    "                     n_epochs=100):\n",
    "    model, model_base_metadata = get_model_and_metadata_from_gcs(bucket, model_dir, \"h5\", load_model, gcs_model_dir, experiment_name)\n",
    "\n",
    "    model_and_metadata_filepath = os.path.join(model_dir, experiment_name)\n",
    "    gcs_model_and_metadata_filepath = os.path.join(gcs_model_dir, experiment_name)\n",
    "    gcs_log_dir = os.path.join(gcs_log_dir, experiment_name)\n",
    "\n",
    "    if model is not None:\n",
    "        print('Resuming training at epoch', int(model_base_metadata['epoch']) + 1)\n",
    "    else:\n",
    "        now = datetime.datetime.utcnow().strftime(\"%Y-%m-%d %H:%M\")\n",
    "        model = start_model\n",
    "        model_base_metadata = {\n",
    "            'data': 'train_valid_google_automl_cloud_and_shadow_dataset_small.csv',\n",
    "            'data_prep': 'normalization_augmentation',\n",
    "            'experiment_name': experiment_name,\n",
    "            'experiment_start_time': now,\n",
    "            'model': 'keras_cnn',\n",
    "            'random_state': random_seed,\n",
    "            # so that initial_epoch is 0\n",
    "            'epoch': -1\n",
    "        }        \n",
    "\n",
    "    print(f'len(train): {len(x_train)}')\n",
    "    print(f'len(valid): {len(x_valid)}')\n",
    "\n",
    "    histories = []\n",
    "    metrics = ['accuracy']\n",
    "    loss = 'binary_crossentropy'\n",
    "    metric_to_monitor = 'val_accuracy'\n",
    "\n",
    "    optimizer = Adam()\n",
    "    model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
    "\n",
    "    verbosity = 0\n",
    "    # Generators\n",
    "    train_generator = AugmentedImageSequenceFromNpy(x=x_train, y=y_train, batch_size=batch_size,\n",
    "                                                    augmentations=None, band_stats=stats)\n",
    "\n",
    "    valid_generator = AugmentedImageSequenceFromNpy(x=x_valid, y=y_valid, batch_size=batch_size,\n",
    "                                                    augmentations=None, band_stats=stats)\n",
    "\n",
    "    callbacks = [\n",
    "#         EarlyStopping(monitor=metric_to_monitor, patience=early_stopping_patience, verbose=verbosity),\n",
    "#         ReduceLROnPlateau(monitor=metric_to_monitor, factor=0.5, patience=early_stopping_patience, min_lr=1e-6),\n",
    "        TensorBoard(gcs_log_dir, histogram_freq=1),\n",
    "        ModelCheckpointGCS(filepath=model_and_metadata_filepath, gcs_filepath=gcs_model_and_metadata_filepath, \n",
    "                           gcs_bucket=bucket, model_metadata=model_base_metadata, monitor=metric_to_monitor, \n",
    "                           verbose=verbosity)\n",
    "    ]\n",
    "\n",
    "    history = model.fit(train_generator, initial_epoch=int(model_base_metadata['epoch']) + 1,\n",
    "                                  epochs=n_epochs,\n",
    "                                  steps_per_epoch=len(train_generator),\n",
    "                                  callbacks=callbacks,\n",
    "                                  validation_data=valid_generator, validation_steps=len(valid_generator),\n",
    "                                  shuffle=True, verbose=1)\n",
    "\n",
    "    actual_y_train, pred_y_train, pred_y_train_probs = train_generator.get_predictions(model)\n",
    "    actual_y_valid, pred_y_valid, pred_y_valid_probs = valid_generator.get_predictions(model)\n",
    "\n",
    "    metadata_filepath = f\"{model_and_metadata_filepath}_metadata.json\"\n",
    "    with open(metadata_filepath, 'r') as json_file:\n",
    "        best_model_metadata = json.load(json_file)\n",
    "\n",
    "    best_model_metadata.update({\n",
    "        'accuracy_train': sklearn.metrics.accuracy_score(actual_y_train, pred_y_train),\n",
    "        'accuracy_valid': sklearn.metrics.accuracy_score(actual_y_valid, pred_y_valid),\n",
    "        'f1_score_train': sklearn.metrics.f1_score(actual_y_train, pred_y_train),\n",
    "        'f1_score_valid': sklearn.metrics.f1_score(actual_y_valid, pred_y_valid),\n",
    "        'confusion_matrix': numpy_to_json(sklearn.metrics.confusion_matrix(actual_y_valid, pred_y_valid)),\n",
    "        'precision_recall_curve': sklearn_precision_recall_curve_to_dict(\n",
    "            sklearn.metrics.precision_recall_curve(actual_y_valid, pred_y_valid)),\n",
    "    })\n",
    "\n",
    "    with open(metadata_filepath, 'w+') as json_file:\n",
    "        json.dump(best_model_metadata, json_file)\n",
    "\n",
    "    blob = bucket.blob(f\"{gcs_model_and_metadata_filepath}_metadata.json\")\n",
    "    blob.upload_from_filename(metadata_filepath)\n",
    "\n",
    "    # Attempt to avoid memory leaks\n",
    "    del train_generator\n",
    "    del valid_generator\n",
    "    gc.collect()\n",
    "    return history\n",
    "\n",
    "# if os.environ.get(\"SHOULD_PREDICT\", \"True\") == \"True\":\n",
    "#     pred_test_labels = predict(model=model, weight_dir=model_path, x=x_test, batch_size=batch_size, n_classes=n_classes)\n",
    "#     clf_report = classification_report(y_test_labels, pred_test_labels, target_names=classes)\n",
    "#     print(clf_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(train): 256\n",
      "len(valid): 256\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n",
      "Train for 2 steps, validate for 2 steps\n",
      "Epoch 1/3\n",
      "1/2 [==============>...............] - ETA: 4s - loss: 0.4389 - accuracy: 1.0000WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (2.222144). Check your callbacks.\n",
      "2/2 [==============================] - 30s 15s/step - loss: 47.7670 - accuracy: 0.5000 - val_loss: 7.8142 - val_accuracy: 0.5469\n",
      "Epoch 2/3\n",
      "2/2 [==============================] - 10s 5s/step - loss: 10.6520 - accuracy: 0.0469 - val_loss: 0.6800 - val_accuracy: 0.5469\n",
      "Epoch 3/3\n",
      "2/2 [==============================] - 11s 6s/step - loss: 0.7885 - accuracy: 0.5000 - val_loss: 0.6864 - val_accuracy: 0.5469\n",
      "Finished training for experiment cloud_and_shadow_basic_cnn_2020_1_31\n"
     ]
    }
   ],
   "source": [
    "experiment_name = f\"{project_name}_basic_cnn_2020_1_31\"\n",
    "history = train_keras_model(bucket=bucket, model_dir=model_dir, gcs_model_dir=gcs_model_dir, gcs_log_dir=gcs_log_dir, \n",
    "                  experiment_name=experiment_name, start_model=basic_cnn_model((120, 120, 3), n_classes=n_classes),\n",
    "                            n_epochs=3)\n",
    "logger.info(f\"Finished training for experiment {experiment_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f5e0485a828>"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading previously trained model.\n",
      "Resuming training at epoch 1\n",
      "len(train): 100\n",
      "len(valid): 100\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 1 steps, validate for 1 steps\n",
      "Epoch 2/3\n",
      "1/1 [==============================] - 20s 20s/step - loss: 1.4209 - accuracy: 0.0400 - val_loss: 5.7233 - val_accuracy: 0.0100\n",
      "Epoch 3/3\n",
      "WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (3.772809). Check your callbacks.\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.6108 - accuracy: 0.0300 - val_loss: 8.5210 - val_accuracy: 0.0000e+00\n",
      "Finished training for experiment cloud_and_shadow_basic_cnn_best_practices_2020_1_31\n",
      "Finished training for experiment cloud_and_shadow_basic_cnn_best_practices_2020_1_31\n"
     ]
    }
   ],
   "source": [
    "# experiment_name = f\"{project_name}_basic_cnn_best_practices_2020_1_31\"\n",
    "# train_keras_model(bucket=bucket, model_dir=model_dir, gcs_model_dir=gcs_model_dir, gcs_log_dir=gcs_log_dir, \n",
    "#                   experiment_name=experiment_name, start_model=basic_cnn_model_with_best_practices((120, 120, 3), n_classes=n_classes))\n",
    "# logger.info(f\"Finished training for experiment {experiment_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import classification_report\n",
    "\n",
    "# test_generator = AugmentedImageSequenceFromNpy(x=x_test, y=None, batch_size=batch_size,\n",
    "#                                                         augmentations=AUGMENTATIONS_TEST)\n",
    "# y_pred = model.predict(test_generator)\n",
    "# y_pred_binary = [0 if pred < .5 else 1 for pred in y_pred]\n",
    "# clf = classification_report(y_test, y_pred_binary,  target_names=['has_clouds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(pd.DataFrame(y_pred)[0].unique())\n",
    "# print(pd.DataFrame(y_pred_binary)[0].unique())\n",
    "# pd.DataFrame(y_pred)[0].unique()\n",
    "# pd.DataFrame(y_pred_binary)[0].unique()\n",
    "# full_histories = join_histories(histories)\n",
    "# graph_model_history(full_histories)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

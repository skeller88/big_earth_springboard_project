{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: albumentations in /opt/conda/lib/python3.7/site-packages (0.4.3)\n",
      "Requirement already satisfied: tensorflow-addons in /opt/conda/lib/python3.7/site-packages (0.7.0)\n",
      "Requirement already satisfied: scipy==1.4.1 in /opt/conda/lib/python3.7/site-packages (1.4.1)\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.7/site-packages (from albumentations) (5.1.2)\n",
      "Requirement already satisfied: numpy>=1.11.1 in /opt/conda/lib/python3.7/site-packages (from albumentations) (1.17.3)\n",
      "Requirement already satisfied: imgaug<0.2.7,>=0.2.5 in /opt/conda/lib/python3.7/site-packages (from albumentations) (0.2.6)\n",
      "Requirement already satisfied: opencv-python-headless>=4.1.1 in /opt/conda/lib/python3.7/site-packages (from albumentations) (4.1.2.30)\n",
      "Requirement already satisfied: tensorflow>=2.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow-addons) (2.1.0)\n",
      "Requirement already satisfied: scikit-image>=0.11.0 in /opt/conda/lib/python3.7/site-packages (from imgaug<0.2.7,>=0.2.5->albumentations) (0.15.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from imgaug<0.2.7,>=0.2.5->albumentations) (1.13.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.1.0->tensorflow-addons) (3.1.0)\n",
      "Requirement already satisfied: tensorboard<2.2.0,>=2.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.1.0->tensorflow-addons) (2.1.0)\n",
      "Requirement already satisfied: gast==0.2.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.1.0->tensorflow-addons) (0.2.2)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.1.0->tensorflow-addons) (3.9.2)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.1.0->tensorflow-addons) (0.33.6)\n",
      "Requirement already satisfied: astor>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.1.0->tensorflow-addons) (0.8.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.1.0->tensorflow-addons) (0.1.8)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.1.0->tensorflow-addons) (1.1.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.1.0->tensorflow-addons) (1.11.2)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.1.0->tensorflow-addons) (0.8.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.1.0->tensorflow-addons) (1.1.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.1.0->tensorflow-addons) (1.25.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.2.0,>=2.1.0rc0 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.1.0->tensorflow-addons) (2.1.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.8 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.1.0->tensorflow-addons) (1.0.8)\n",
      "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (3.1.2)\n",
      "Requirement already satisfied: networkx>=2.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (2.4)\n",
      "Requirement already satisfied: pillow>=4.3.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (6.2.1)\n",
      "Requirement already satisfied: imageio>=2.0.1 in /opt/conda/lib/python3.7/site-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (2.6.1)\n",
      "Requirement already satisfied: PyWavelets>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (1.1.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow>=2.1.0->tensorflow-addons) (0.4.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow>=2.1.0->tensorflow-addons) (3.1.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow>=2.1.0->tensorflow-addons) (0.16.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow>=2.1.0->tensorflow-addons) (42.0.2.post20191201)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow>=2.1.0->tensorflow-addons) (1.7.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow>=2.1.0->tensorflow-addons) (2.22.0)\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (from keras-applications>=1.0.8->tensorflow>=2.1.0->tensorflow-addons) (2.9.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (2.4.5)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (2.8.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (1.1.0)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.7/site-packages (from networkx>=2.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (4.4.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow>=2.1.0->tensorflow-addons) (1.3.0)\n",
      "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow>=2.1.0->tensorflow-addons) (3.1.1)\n",
      "Requirement already satisfied: rsa<4.1,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow>=2.1.0->tensorflow-addons) (4.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow>=2.1.0->tensorflow-addons) (0.2.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow>=2.1.0->tensorflow-addons) (2019.11.28)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow>=2.1.0->tensorflow-addons) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow>=2.1.0->tensorflow-addons) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow>=2.1.0->tensorflow-addons) (1.25.7)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow>=2.1.0->tensorflow-addons) (3.0.1)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /opt/conda/lib/python3.7/site-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow>=2.1.0->tensorflow-addons) (0.4.8)\n"
     ]
    }
   ],
   "source": [
    "!pip install albumentations tensorflow-addons scipy==1.4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "from collections import defaultdict\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "from typing import List, Tuple\n",
    "\n",
    "from albumentations import (\n",
    "    Compose, Flip, Rotate\n",
    ")\n",
    "\n",
    "from data_science.augmented_image_sequence_from_npy import AugmentedImageSequenceFromNpy\n",
    "\n",
    "import gc\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TensorBoard\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Input\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.metrics import Accuracy, Precision, Recall\n",
    "\n",
    "from tensorflow_addons.metrics import FBetaScore, F1Score\n",
    "\n",
    "import random\n",
    "\n",
    "pal = sns.color_palette()\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight_path /home/jovyan/work/data/big_earth/model/model_weights/model_basic_cnn_20200121-203404_{epoch:02d}-{val_loss:.2f}.hdf5\n",
      "['/home/jovyan/work/data/big_earth/npy_image_files/S2B_MSIL2A_20170801T095029_6_66.npy'\n",
      " '/home/jovyan/work/data/big_earth/npy_image_files/S2B_MSIL2A_20180515T094029_40_73.npy'\n",
      " '/home/jovyan/work/data/big_earth/npy_image_files/S2B_MSIL2A_20171112T114339_43_30.npy'\n",
      " '/home/jovyan/work/data/big_earth/npy_image_files/S2A_MSIL2A_20180527T093041_65_35.npy'\n",
      " '/home/jovyan/work/data/big_earth/npy_image_files/S2B_MSIL2A_20180224T112109_16_25.npy']\n",
      "len(df) 490 len(df_cloud_and_shadow) 6 len(df_no_cloud_or_snow) 437 len(sample_no_cloud_or_snow) 6\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "random_seed = 0\n",
    "random.seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "tf.random.set_seed(random_seed)\n",
    "\n",
    "root = os.environ.get(\"ROOT\", '/home/jovyan/work')\n",
    "experiment_name = \"basic_cnn_\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "big_earth = os.path.join(root, 'data', 'big_earth')\n",
    "metadata_path = os.path.join(big_earth, 'metadata', 'metadata.csv')\n",
    "train_path = os.path.join(big_earth, 'npy_image_files')\n",
    "test_path = train_path\n",
    "\n",
    "weight_dir = os.path.join(big_earth, 'model', 'model_weights')\n",
    "log_dir = os.path.join(big_earth, 'model', 'logs', experiment_name)\n",
    "\n",
    "for dir_to_create in [weight_dir, log_dir]:\n",
    "    if not os.path.exists(dir_to_create):\n",
    "        os.makedirs(dir_to_create)\n",
    "\n",
    "# ModelCheckpoint expects a path\n",
    "weight_path = os.environ.get(\"WEIGHT_PATH\",\n",
    "    os.path.join(weight_dir, 'model_' + experiment_name + '_{epoch:02d}-{val_loss:.2f}.hdf5'))\n",
    "print('weight_path', weight_path)\n",
    "\n",
    "files = pd.Index(os.listdir(train_path)).str.replace(\".npy\", \"\")\n",
    "df = pd.read_csv(metadata_path)\n",
    "df = df.set_index('image_prefix', drop=False)\n",
    "df = df.loc[df.index.intersection(files)]\n",
    "df['image_prefix'] = (train_path + \"/\" + df['image_prefix'] + \".npy\")\n",
    "\n",
    "# sanity check paths\n",
    "print(df.head(5)['image_prefix'].values)\n",
    "\n",
    "df_cloud_and_shadow = df[(df['has_cloud_and_shadow'] == 1)]\n",
    "df_no_cloud_or_snow = df[(df['has_cloud_and_shadow'] == 0) & (df['has_snow'] == 0)]\n",
    "sample_no_cloud_or_snow = df_no_cloud_or_snow.sample(n=len(df_cloud_and_shadow))\n",
    "print(\n",
    "    'len(df)', len(df), \n",
    "    'len(df_cloud_and_shadow)', len(df_cloud_and_shadow), \n",
    "    \"len(df_no_cloud_or_snow)\", len(df_no_cloud_or_snow),\n",
    "    'len(sample_no_cloud_or_snow)', len(sample_no_cloud_or_snow), \n",
    "     )\n",
    "\n",
    "# 44 level 3 classes:\n",
    "# Currently using:\n",
    "# https://land.copernicus.eu/user-corner/technical-library/corine-land-cover-nomenclature-guidelines/html/\n",
    "classes = [\"Continuous urban fabric\", \"Discontinuous urban fabric\", \"Industrial or commercial units\",\n",
    "       \"Road and rail networks and associated land\", \"Port areas\", \"Airports\", \"Mineral extraction sites\",\n",
    "       \"Dump sites\",\n",
    "       \"Construction sites\", \"Green urban areas\", \"Sport and leisure facilities\", \"Non-irrigated arable land\",\n",
    "       \"Permanently irrigated land\", \"Rice fields\", \"Vineyards\", \"Fruit trees and berry plantations\",\n",
    "       \"Olive groves\",\n",
    "       \"Pastures\", \"Annual crops associated with permanent crops\", \"Complex cultivation patterns\",\n",
    "       \"Land principally occupied by agriculture, with significant areas of natural vegetation\",\n",
    "       \"Agro-forestry areas\",\n",
    "       \"Broad-leaved forest\", \"Coniferous forest\", \"Mixed forest\", \"Natural grassland\", \"Moors and heathland\",\n",
    "       \"Sclerophyllous vegetation\", \"Transitional woodland/shrub\", \"Beaches, dunes, sands\", \"Bare rock\",\n",
    "       \"Sparsely vegetated areas\", \"Burnt areas\", \"Glaciers and perpetual snow\", \"Inland marshes\", \"Peatbogs\",\n",
    "       \"Salt marshes\", \"Salines\", \"Intertidal flats\", \"Water courses\", \"Water bodies\", \"Coastal lagoons\",\n",
    "       \"Estuaries\",\n",
    "       \"Sea and ocean\"]\n",
    "\n",
    "# n_classes = len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(train) 8 len(valid) 3 len(test) 1\n"
     ]
    }
   ],
   "source": [
    "def balanced_class_train_test_splits(*dataframes: List[pd.DataFrame]):\n",
    "    train = []\n",
    "    valid = []\n",
    "    test = []\n",
    "\n",
    "    for dataframe in dataframes:\n",
    "        random_mask = np.random.rand(len(dataframe))\n",
    "        train_mask = random_mask < 0.6\n",
    "        valid_mask = (0.6 <= random_mask) & (random_mask < 0.8)\n",
    "        test_mask = random_mask >= 0.8\n",
    "\n",
    "        train.append(dataframe[train_mask])\n",
    "        valid.append(dataframe[valid_mask])\n",
    "        test.append(dataframe[test_mask])\n",
    "\n",
    "    train = pd.concat(train)\n",
    "    valid = pd.concat(valid)\n",
    "    test = pd.concat(test)\n",
    "    \n",
    "    print(\"len(train)\", len(train), \"len(valid)\", len(valid), \"len(test)\", len(test))\n",
    "    return train, valid, test\n",
    "\n",
    "def basic_cnn_model(img_shape, n_classes):\n",
    "    \"\"\"\n",
    "    From https://arxiv.org/pdf/1902.06148.pdf\n",
    "\n",
    "    To this end, we selected a shallow CNN architecture, which consists of three convolutional layers with 32, 32 and\n",
    "    64 filters having 5 × 5, 5 × 5 and 3 × 3 filter sizes, respectively. We\n",
    "    added one fully connected (FC) layer and one classification\n",
    "    layer to the output of last convolutional layer. In all convolution operations, zero padding was used. We also applied\n",
    "    max-pooling between layers.\n",
    "    \"\"\"\n",
    "    img_inputs = Input(shape=img_shape)\n",
    "    conv_1 = Conv2D(32, (5, 5), activation='relu')(img_inputs)\n",
    "    maxpool_1 = MaxPooling2D((2, 2))(conv_1)\n",
    "    conv_2 = Conv2D(32, (5, 5), activation='relu')(maxpool_1)\n",
    "    maxpool_2 = MaxPooling2D((2, 2))(conv_2)\n",
    "    conv_3 = Conv2D(64, (3, 3), activation='relu')(maxpool_2)\n",
    "    flatten = Flatten()(conv_3)\n",
    "    dense_1 = Dense(64, activation='relu')(flatten)\n",
    "    output = Dense(n_classes, activation='sigmoid')(dense_1)\n",
    "\n",
    "    return Model(inputs=img_inputs, outputs=output)\n",
    "\n",
    "\n",
    "def pretrained_model(base_model_class, input_shape, output_shape):\n",
    "    \"\"\"\n",
    "    All of the top performers use transfer learning and image augmentation: https://www.kaggle.com/c/planet-understanding-the-amazon-from-space/discussion/33559\n",
    "\n",
    "    Another useful discussion on both topics: https://www.kaggle.com/c/planet-understanding-the-amazon-from-space/discussion/36091#202629\n",
    "    \"\"\"\n",
    "    # from https://www.kaggle.com/sashakorekov/end-to-end-resnet50-with-tta-lb-0-93#L321\n",
    "    base_model = base_model_class(include_top=False, input_shape=input_shape, pooling='avg', weights='imagenet')\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    x = base_model.output\n",
    "    x = Dense(2048, activation='relu')(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    output = Dense(output_shape, activation='sigmoid')(x)\n",
    "    model = Model(inputs=base_model.inputs, outputs=output)\n",
    "    model.name = base_model.name\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def train(model, x_train: np.array, y_train: np.array, x_valid: np.array,\n",
    "          y_valid: np.array, n_epochs, n_classes, batch_size, log_dir, weight_path):\n",
    "    \"\"\"\n",
    "    Based on from https://www.kaggle.com/infinitewing/keras-solution-and-my-experience-0-92664\n",
    "    \"\"\"\n",
    "    print(f'Split train: {len(x_train)}')\n",
    "    print(f'Split valid: {len(x_valid)}')\n",
    "\n",
    "    histories = []\n",
    "    learn_rates = [0.001, 0.0001, 0.00001]\n",
    "    metrics = [Accuracy(), Precision(), Recall(), F1Score(num_classes=n_classes, average='micro'),\n",
    "               FBetaScore(num_classes=n_classes, beta=2.0, average='micro')]\n",
    "    loss = 'binary_crossentropy'\n",
    "    metric_to_monitor = 'val_loss'\n",
    "\n",
    "    for learn_rate_num, learn_rate in enumerate(learn_rates):\n",
    "        print(f'Training model on fold with learn_rate {learn_rate}')\n",
    "        optimizer = Adam(lr=learn_rate, momentum=0.9)\n",
    "        model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
    "\n",
    "        verbosity = 0\n",
    "        callbacks = [\n",
    "            EarlyStopping(monitor=metric_to_monitor, patience=2, verbose=verbosity),\n",
    "            ReduceLROnPlateau(monitor=metric_to_monitor, factor=0.5, patience=2, min_lr=0.000001),\n",
    "            TensorBoard(log_dir, histogram_freq=1),\n",
    "            ModelCheckpoint(weight_path, monitor=metric_to_monitor, save_weights_only=False, save_best_only=True,\n",
    "                            verbose=verbosity)\n",
    "        ]\n",
    "\n",
    "        # Generators\n",
    "        train_generator = AugmentedImageSequenceFromNpy(x=x_train, y=y_train, batch_size=batch_size,\n",
    "                                                        augmentations=AUGMENTATIONS_TRAIN)\n",
    "\n",
    "        valid_generator = AugmentedImageSequenceFromNpy(x=x_valid, y=y_valid, batch_size=batch_size,\n",
    "                                                        augmentations=AUGMENTATIONS_TEST)\n",
    "\n",
    "        history = model.fit_generator(generator=train_generator,\n",
    "                                      epochs=n_epochs,\n",
    "                                      steps_per_epoch=len(train_generator),\n",
    "                                      callbacks=callbacks,\n",
    "                                      validation_data=valid_generator, validation_steps=len(valid_generator),\n",
    "                                      shuffle=True, verbose=1)\n",
    "        histories.append(history)\n",
    "\n",
    "    # Attempt to avoid memory leaks\n",
    "    del train_generator\n",
    "    del valid_generator\n",
    "    gc.collect()\n",
    "\n",
    "    return histories\n",
    "\n",
    "\n",
    "def join_histories(histories):\n",
    "    full_history = defaultdict(list)\n",
    "\n",
    "    for history in histories:\n",
    "        for key, value in history.history.items():\n",
    "            full_history[key].extend(value)\n",
    "    return full_history\n",
    "\n",
    "\n",
    "def graph_model_history(history):\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    t = f.suptitle('Basic CNN Performance', fontsize=12)\n",
    "    f.subplots_adjust(top=0.85, wspace=0.3)\n",
    "\n",
    "    max_epoch = len(history['val_loss']) + 1\n",
    "    epoch_list = list(range(1, max_epoch))\n",
    "    ax1.plot(epoch_list, history['accuracy'], label='Train Accuracy')\n",
    "    ax1.plot(epoch_list, history['val_accuracy'], label='Validation Accuracy')\n",
    "    ax1.set_xticks(np.arange(1, max_epoch, 5))\n",
    "    ax1.set_ylabel('Accuracy Value')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_title('Accuracy')\n",
    "    l1 = ax1.legend(loc=\"best\")\n",
    "\n",
    "    ax2.plot(epoch_list, history['loss'], label='Train Loss')\n",
    "    ax2.plot(epoch_list, history['val_loss'], label='Validation Loss')\n",
    "    ax2.set_xticks(np.arange(1, max_epoch, 5))\n",
    "    ax2.set_ylabel('Loss Value')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_title('Loss')\n",
    "    l2 = ax2.legend(loc=\"best\")\n",
    "\n",
    "\n",
    "def predict(model, weight_dir, x, batch_size, n_classes):\n",
    "    thresholds = np.array([0.5 for _ in range(n_classes)])\n",
    "\n",
    "    weight_path = os.path.join(weight_dir, 'weights_kfold_' + str(num_fold) + '.h5')\n",
    "    model.load_weights(weight_path)\n",
    "\n",
    "    predict_generator = AugmentedImageSequenceFromNpy(x=x, y=None, batch_size=batch_size,\n",
    "                                                        augmentations=AUGMENTATIONS_TEST)\n",
    "    # Generators\n",
    "    pred_test_probs = model.predict_generator(predict_generator)\n",
    "    pred_test_labels = pd.DataFrame(pred_test_probs, columns=classes)\n",
    "    pred_test_labels = pred_test_labels.apply(lambda x: x > thresholds, axis=1)\n",
    "    # Convert boolean predictions to labels\n",
    "    pred_test_lables = pred_test_labels.apply(lambda row: ' '.join(row[row].index), axis=1)\n",
    "\n",
    "    del predict_generator\n",
    "    gc.collect()\n",
    "\n",
    "    return pred_test_labels\n",
    "\n",
    "train, valid, test = balanced_class_train_test_splits(\n",
    "    *[sample_no_cloud_or_snow, df_cloud_and_shadow])\n",
    "\n",
    "AUGMENTATIONS_TRAIN = Compose([\n",
    "    Flip(p=0.5),\n",
    "    Rotate(limit=(0, 360), p=0.5)\n",
    "])\n",
    "\n",
    "AUGMENTATIONS_TEST = Compose([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 1\n",
    "\n",
    "n_epochs = 100\n",
    "model = basic_cnn_model((120, 120, 3), n_classes=n_classes)\n",
    "\n",
    "# Test the correctness and speed of loading one batch\n",
    "batch_size = 128\n",
    "test_data_len = batch_size * 2\n",
    "\n",
    "x_train = train['image_prefix'].values\n",
    "x_valid = valid['image_prefix'].values\n",
    "x_test = test['image_prefix'].values\n",
    "\n",
    "y_train = np.random.randint(0, 2, (len(train), n_classes))\n",
    "y_valid = np.random.randint(0, 2, (len(valid), n_classes))\n",
    "y_test = np.random.randint(0, 2, (len(test), n_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8,) (8, 1) (1,) int64\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, y_train.shape, y_train[0].shape, y_train.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 120, 120, 3) (8, 1)\n",
      "Split train: 8\n",
      "Split valid: 3\n",
      "Training model on fold with learn_rate 0.001\n",
      "WARNING:tensorflow:From <ipython-input-4-10e22830400f>:80: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 1 steps, validate for 1 steps\n",
      "Epoch 1/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 26.4005 - accuracy: 0.1250 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_score: 0.5000 - fbeta_score: 0.3846 - val_loss: 396.2237 - val_accuracy: 0.6667 - val_precision: 0.6667 - val_recall: 1.0000 - val_f1_score: 0.8000 - val_fbeta_score: 0.9091\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 1s 797ms/step - loss: 2768.0317 - accuracy: 0.3750 - precision: 0.3750 - recall: 1.0000 - f1_score: 0.5455 - fbeta_score: 0.7500 - val_loss: 44.9131 - val_accuracy: 0.6667 - val_precision: 0.6667 - val_recall: 1.0000 - val_f1_score: 0.8000 - val_fbeta_score: 0.9091\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 1s 501ms/step - loss: 361.3700 - accuracy: 0.3750 - precision: 0.3750 - recall: 1.0000 - f1_score: 0.5455 - fbeta_score: 0.7500 - val_loss: 959.5791 - val_accuracy: 0.3333 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_score: 0.0000e+00 - val_fbeta_score: 0.0000e+00\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 421ms/step - loss: 394.5670 - accuracy: 0.6250 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_score: 0.0000e+00 - fbeta_score: 0.0000e+00 - val_loss: 612.0061 - val_accuracy: 0.3333 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_score: 0.0000e+00 - val_fbeta_score: 0.0000e+00\n",
      "Training model on fold with learn_rate 0.0001\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 1 steps, validate for 1 steps\n",
      "Epoch 1/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 256.1124 - accuracy: 0.6250 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_score: 0.0000e+00 - fbeta_score: 0.0000e+00 - val_loss: 494.9018 - val_accuracy: 0.3333 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_score: 0.0000e+00 - val_fbeta_score: 0.0000e+00\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 1s 681ms/step - loss: 204.6062 - accuracy: 0.6250 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_score: 0.0000e+00 - fbeta_score: 0.0000e+00 - val_loss: 394.3546 - val_accuracy: 0.3333 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_score: 0.0000e+00 - val_fbeta_score: 0.0000e+00\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 1s 541ms/step - loss: 162.3147 - accuracy: 0.6250 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_score: 0.0000e+00 - fbeta_score: 0.0000e+00 - val_loss: 306.1116 - val_accuracy: 0.3333 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_score: 0.0000e+00 - val_fbeta_score: 0.0000e+00\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 1s 574ms/step - loss: 126.2599 - accuracy: 0.6250 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_score: 0.0000e+00 - fbeta_score: 0.0000e+00 - val_loss: 226.2109 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_score: 0.0000e+00 - val_fbeta_score: 0.0000e+00\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 1s 524ms/step - loss: 98.8006 - accuracy: 0.6250 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_score: 0.0000e+00 - fbeta_score: 0.0000e+00 - val_loss: 152.9424 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_score: 0.0000e+00 - val_fbeta_score: 0.0000e+00\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 1s 523ms/step - loss: 69.8446 - accuracy: 0.5000 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_score: 0.0000e+00 - fbeta_score: 0.0000e+00 - val_loss: 83.9791 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_score: 0.0000e+00 - val_fbeta_score: 0.0000e+00\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 1s 837ms/step - loss: 35.1073 - accuracy: 0.3750 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_score: 0.0000e+00 - fbeta_score: 0.0000e+00 - val_loss: 18.8876 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1_score: 0.0000e+00 - val_fbeta_score: 0.0000e+00\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 1s 824ms/step - loss: 11.0732 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_score: 0.5714 - fbeta_score: 0.6250 - val_loss: 2.8516 - val_accuracy: 0.6667 - val_precision: 0.6667 - val_recall: 1.0000 - val_f1_score: 0.8000 - val_fbeta_score: 0.9091\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 397ms/step - loss: 8.9730 - accuracy: 0.2500 - precision: 0.3333 - recall: 0.6667 - f1_score: 0.5455 - fbeta_score: 0.7500 - val_loss: 4.4995 - val_accuracy: 0.6667 - val_precision: 0.6667 - val_recall: 1.0000 - val_f1_score: 0.8000 - val_fbeta_score: 0.9091\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 375ms/step - loss: 20.6499 - accuracy: 0.3750 - precision: 0.4286 - recall: 1.0000 - f1_score: 0.5455 - fbeta_score: 0.7500 - val_loss: 5.0506 - val_accuracy: 0.6667 - val_precision: 0.6667 - val_recall: 1.0000 - val_f1_score: 0.8000 - val_fbeta_score: 0.9091\n",
      "Training model on fold with learn_rate 1e-05\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 1 steps, validate for 1 steps\n",
      "Epoch 1/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 26.4482 - accuracy: 0.3750 - precision: 0.3750 - recall: 1.0000 - f1_score: 0.5455 - fbeta_score: 0.7500 - val_loss: 4.8756 - val_accuracy: 0.6667 - val_precision: 0.6667 - val_recall: 1.0000 - val_f1_score: 0.8000 - val_fbeta_score: 0.9091\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 1s 646ms/step - loss: 26.5815 - accuracy: 0.3750 - precision: 0.3750 - recall: 1.0000 - f1_score: 0.5455 - fbeta_score: 0.7500 - val_loss: 4.6854 - val_accuracy: 0.6667 - val_precision: 0.6667 - val_recall: 1.0000 - val_f1_score: 0.8000 - val_fbeta_score: 0.9091\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 1s 710ms/step - loss: 21.2877 - accuracy: 0.3750 - precision: 0.3750 - recall: 1.0000 - f1_score: 0.5455 - fbeta_score: 0.7500 - val_loss: 4.4738 - val_accuracy: 0.6667 - val_precision: 0.6667 - val_recall: 1.0000 - val_f1_score: 0.8000 - val_fbeta_score: 0.9091\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 1s 670ms/step - loss: 28.0758 - accuracy: 0.3750 - precision: 0.3750 - recall: 1.0000 - f1_score: 0.5455 - fbeta_score: 0.7500 - val_loss: 4.2210 - val_accuracy: 0.6667 - val_precision: 0.6667 - val_recall: 1.0000 - val_f1_score: 0.8000 - val_fbeta_score: 0.9091\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 1s 595ms/step - loss: 16.4269 - accuracy: 0.3750 - precision: 0.3750 - recall: 1.0000 - f1_score: 0.5455 - fbeta_score: 0.7500 - val_loss: 3.9753 - val_accuracy: 0.6667 - val_precision: 0.6667 - val_recall: 1.0000 - val_f1_score: 0.8000 - val_fbeta_score: 0.9091\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 1s 619ms/step - loss: 14.8684 - accuracy: 0.3750 - precision: 0.4286 - recall: 1.0000 - f1_score: 0.5455 - fbeta_score: 0.7500 - val_loss: 3.7566 - val_accuracy: 0.6667 - val_precision: 0.6667 - val_recall: 1.0000 - val_f1_score: 0.8000 - val_fbeta_score: 0.9091\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 1s 642ms/step - loss: 12.7879 - accuracy: 0.3750 - precision: 0.4286 - recall: 1.0000 - f1_score: 0.5455 - fbeta_score: 0.7500 - val_loss: 3.5181 - val_accuracy: 0.6667 - val_precision: 0.6667 - val_recall: 1.0000 - val_f1_score: 0.8000 - val_fbeta_score: 0.9091\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 1s 688ms/step - loss: 14.4438 - accuracy: 0.3750 - precision: 0.3750 - recall: 1.0000 - f1_score: 0.5455 - fbeta_score: 0.7500 - val_loss: 3.2782 - val_accuracy: 0.6667 - val_precision: 0.6667 - val_recall: 1.0000 - val_f1_score: 0.8000 - val_fbeta_score: 0.9091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/100\n",
      "1/1 [==============================] - 1s 664ms/step - loss: 14.5081 - accuracy: 0.3750 - precision: 0.3750 - recall: 1.0000 - f1_score: 0.5455 - fbeta_score: 0.7500 - val_loss: 3.0188 - val_accuracy: 0.6667 - val_precision: 0.6667 - val_recall: 1.0000 - val_f1_score: 0.8000 - val_fbeta_score: 0.9091\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 1s 773ms/step - loss: 12.7662 - accuracy: 0.3750 - precision: 0.5000 - recall: 1.0000 - f1_score: 0.6000 - fbeta_score: 0.7895 - val_loss: 2.7299 - val_accuracy: 0.6667 - val_precision: 0.6667 - val_recall: 1.0000 - val_f1_score: 0.8000 - val_fbeta_score: 0.9091\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 1s 665ms/step - loss: 9.5056 - accuracy: 0.3750 - precision: 0.3750 - recall: 1.0000 - f1_score: 0.5455 - fbeta_score: 0.7500 - val_loss: 2.4387 - val_accuracy: 0.6667 - val_precision: 0.6667 - val_recall: 1.0000 - val_f1_score: 0.8000 - val_fbeta_score: 0.9091\n",
      "Epoch 12/100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-10e22830400f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     78\u001b[0m                                       \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m                                       \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m                                       shuffle=True, verbose=1)\n\u001b[0m\u001b[1;32m     81\u001b[0m         \u001b[0mhistories\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m               instructions)\n\u001b[0;32m--> 324\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[1;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1304\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1305\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m   @deprecation.deprecated(\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    395\u001b[0m                       total_epochs=1)\n\u001b[1;32m    396\u001b[0m                   cbks.make_logs(model, epoch_logs, eval_result, ModeKeys.TEST,\n\u001b[0;32m--> 397\u001b[0;31m                                  prefix='val_')\n\u001b[0m\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mon_epoch\u001b[0;34m(self, epoch, mode)\u001b[0m\n\u001b[1;32m    769\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m         \u001b[0;31m# Epochs only apply to `fit`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 771\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    772\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m    300\u001b[0m     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m       \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m    990\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    991\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 992\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    993\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    994\u001b[0m       \u001b[0;31m# For multi-worker training, back up the weights and current training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_save_model\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m   1027\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m               \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1029\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1030\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, filepath, overwrite, include_optimizer, save_format, signatures, options)\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \"\"\"\n\u001b[1;32m   1007\u001b[0m     save.save_model(self, filepath, overwrite, include_optimizer, save_format,\n\u001b[0;32m-> 1008\u001b[0;31m                     signatures, options)\n\u001b[0m\u001b[1;32m   1009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1010\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/save.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(model, filepath, overwrite, include_optimizer, save_format, signatures, options)\u001b[0m\n\u001b[1;32m    110\u001b[0m           'or using `save_weights`.')\n\u001b[1;32m    111\u001b[0m     hdf5_format.save_model_to_hdf5(\n\u001b[0;32m--> 112\u001b[0;31m         model, filepath, overwrite, include_optimizer)\n\u001b[0m\u001b[1;32m    113\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m     saved_model_save.save(model, filepath, overwrite, include_optimizer,\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py\u001b[0m in \u001b[0;36msave_model_to_hdf5\u001b[0;34m(model, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[1;32m    113\u001b[0m     if (include_optimizer and model.optimizer and\n\u001b[1;32m    114\u001b[0m         not isinstance(model.optimizer, optimizers.TFOptimizer)):\n\u001b[0;32m--> 115\u001b[0;31m       \u001b[0msave_optimizer_weights_to_hdf5_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py\u001b[0m in \u001b[0;36msave_optimizer_weights_to_hdf5_group\u001b[0;34m(hdf5_group, optimizer)\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0mparam_dset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 592\u001b[0;31m         \u001b[0mparam_dset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    593\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/h5py/_hl/dataset.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, args, val)\u001b[0m\n\u001b[1;32m    706\u001b[0m         \u001b[0mmspace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_simple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmshape_pad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mh5s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUNLIMITED\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmshape_pad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfspace\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mselection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdxpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dxpl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread_direct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource_sel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdest_sel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# y_train = np.random.randint(0, 2, (len(train), 44))\n",
    "# y_valid = np.random.randint(0, 2, (len(valid), 44))\n",
    "# y_test = np.random.randint(0, 2, (len(test), 44))\n",
    "# y_test_labels = test['labels'].values\n",
    "\n",
    "a = AugmentedImageSequenceFromNpy(x=x_train[:test_data_len], y=y_train[:test_data_len],\n",
    "                                  batch_size=len(x_train[:test_data_len]),\n",
    "                                  augmentations=AUGMENTATIONS_TRAIN)\n",
    "\n",
    "for x, y in a:\n",
    "    print(x.shape, y.shape)\n",
    "    break\n",
    "\n",
    "a.on_epoch_end()\n",
    "\n",
    "if os.environ.get(\"SHOULD_TRAIN\", \"True\") == \"True\":\n",
    "#     histories = train(model, x_train=x_train,\n",
    "#                       y_train=y_train,\n",
    "#                       x_valid=x_valid,\n",
    "#                       y_valid=y_valid,\n",
    "#                       n_epochs=n_epochs,\n",
    "#                       n_classes=n_classes,\n",
    "#                       batch_size=batch_size,\n",
    "#                       log_dir=log_dir,\n",
    "#                       weight_path=weight_path)\n",
    "    \n",
    "    print(f'Split train: {len(x_train)}')\n",
    "    print(f'Split valid: {len(x_valid)}')\n",
    "\n",
    "    histories = []\n",
    "    learn_rates = [0.001, 0.0001, 0.00001]\n",
    "    metrics = [Accuracy(), Precision(), Recall(), F1Score(num_classes=n_classes, average='micro'),\n",
    "               FBetaScore(num_classes=n_classes, beta=2.0, average='micro')]\n",
    "    loss = 'binary_crossentropy'\n",
    "    metric_to_monitor = 'val_loss'\n",
    "\n",
    "    for learn_rate_num, learn_rate in enumerate(learn_rates):\n",
    "        print(f'Training model on fold with learn_rate {learn_rate}')\n",
    "        optimizer = Adam(lr=learn_rate)\n",
    "        model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
    "\n",
    "        verbosity = 0\n",
    "        callbacks = [\n",
    "            EarlyStopping(monitor=metric_to_monitor, patience=2, verbose=verbosity),\n",
    "            ReduceLROnPlateau(monitor=metric_to_monitor, factor=0.5, patience=2, min_lr=0.000001),\n",
    "            TensorBoard(log_dir, histogram_freq=1),\n",
    "            ModelCheckpoint(weight_path, monitor=metric_to_monitor, save_weights_only=False, save_best_only=True,\n",
    "                            verbose=verbosity)\n",
    "        ]\n",
    "\n",
    "        # Generators\n",
    "        train_generator = AugmentedImageSequenceFromNpy(x=x_train, y=y_train, batch_size=batch_size,\n",
    "                                                        augmentations=AUGMENTATIONS_TRAIN)\n",
    "\n",
    "        valid_generator = AugmentedImageSequenceFromNpy(x=x_valid, y=y_valid, batch_size=batch_size,\n",
    "                                                        augmentations=AUGMENTATIONS_TEST)\n",
    "\n",
    "        history = model.fit_generator(generator=train_generator,\n",
    "                                      epochs=n_epochs,\n",
    "                                      steps_per_epoch=len(train_generator),\n",
    "                                      callbacks=callbacks,\n",
    "                                      validation_data=valid_generator, validation_steps=len(valid_generator),\n",
    "                                      shuffle=True, verbose=1)\n",
    "        histories.append(history)\n",
    "\n",
    "    # Attempt to avoid memory leaks\n",
    "    del train_generator\n",
    "    del valid_generator\n",
    "    gc.collect()\n",
    "    \n",
    "    \n",
    "\n",
    "# if os.environ.get(\"SHOULD_PREDICT\", \"True\") == \"True\":\n",
    "#     pred_test_labels = predict(model=model, weight_dir=weight_dir, x=x_test, batch_size=batch_size, n_classes=n_classes)\n",
    "#     clf_report = classification_report(y_test_labels, pred_test_labels, target_names=classes)\n",
    "#     print(clf_report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# conda environments:\r\n",
      "#\r\n",
      "base                  *  /opt/conda\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!conda env list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/bin/python\n",
      "['/home/jovyan/work/Documents/big_earth_springboard_project/data_science', '/opt/conda/lib/python37.zip', '/opt/conda/lib/python3.7', '/opt/conda/lib/python3.7/lib-dynload', '', '/opt/conda/lib/python3.7/site-packages', '/opt/conda/lib/python3.7/site-packages/IPython/extensions', '/home/jovyan/.ipython']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "print(sys.path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import gc\n",
    "from joblib import dump, load\n",
    "import random\n",
    "import time\n",
    "from typing import List, Tuple\n",
    "\n",
    "from albumentations import (\n",
    "    Compose, Flip, Rotate\n",
    ")\n",
    "\n",
    "import dask\n",
    "import dask.array as da\n",
    "from google.cloud import storage\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_recall_fscore_support, precision_score, precision_recall_curve\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TensorBoard\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.metrics import Accuracy\n",
    "\n",
    "from data_engineering.dask_image_stats_collector import stats_for_numpy_images \n",
    "from data_science.augmented_image_sequence_from_npy import AugmentedImageSequenceFromNpy\n",
    "from data_science.keras.model_checkpoint_gcs import ModelCheckpointGCS\n",
    "from data_science.keras.cnn_models import basic_cnn_model, basic_cnn_model_with_best_practices\n",
    "from data_science.serialization_utils import numpy_to_json, sklearn_precision_recall_curve_to_dict\n",
    "from data_science.sklearn_batch_generator import SklearnBatchGenerator\n",
    "from data_science.train import get_model_and_metadata_from_gcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "n_classes = 1\n",
    "n_epochs = 100\n",
    "batch_size = 128\n",
    "\n",
    "early_stopping_patience = 6\n",
    "\n",
    "use_small_dataset = True\n",
    "use_random_small_dataset = False\n",
    "\n",
    "root = '/home/jovyan/work/data/big_earth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 57), started 0:08:56 ago. (Use '!kill 57' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-b46f792f93ede7db\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-b46f792f93ede7db\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 6006;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir \"gs://big_earth/model/logs/cloud_and_shadow_basic_cnn_2020_1_31\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "\n",
    "logger = logging.getLogger('papermill')\n",
    "handler = logging.StreamHandler(sys.stdout)\n",
    "logger.addHandler(handler)\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = '/app/.gcs/big-earth-252219-fb2e5c109f78.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root: /home/jovyan/work/data/big_earth\n"
     ]
    }
   ],
   "source": [
    "logger.info(f\"root: {root}\")\n",
    "pal = sns.color_palette()\n",
    "\n",
    "random_seed = 0\n",
    "random.seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "tf.random.set_seed(random_seed)\n",
    "\n",
    "project_name = \"cloud_and_shadow\"\n",
    "model_dir = os.path.join(root, \"model/models\")\n",
    "# blob prefix\n",
    "gcs_model_dir = \"model/models\"\n",
    "# tensorboard\n",
    "gcs_log_dir = \"gs://big_earth/model/logs\"\n",
    "\n",
    "for directory in [model_dir]:\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory, exist_ok=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n"
     ]
    }
   ],
   "source": [
    "logger.info('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcs_client = storage.Client()\n",
    "bucket = gcs_client.bucket(\"big_earth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 44)\n",
      "(1,)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "# np.array(json.loads(df['binarized_labels'].iloc[0])).shape\n",
    "\n",
    "def prepare_data(df):\n",
    "    df['has_cloud_and_shadow_target'] = df['has_cloud_and_shadow_target'].apply(lambda x: np.array(json.loads(x)))\n",
    "    df['binarized_labels'] = df['binarized_labels'].apply(lambda x: np.array(json.loads(x)))    \n",
    "    df['image_path'] = root + \"/npy_image_files/\" + df['image_prefix'] + \".npy\"\n",
    "    return df\n",
    "\n",
    "df = pd.read_csv(root + \"/metadata/metadata.csv\")\n",
    "df = prepare_data(df)\n",
    "logger.info(df['binarized_labels'].iloc[0].shape)\n",
    "logger.info(df['has_cloud_and_shadow_target'].iloc[0].shape)\n",
    "df = df.set_index('image_prefix', drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1907 253 240\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# len(pd.read_csv(root + '/google_automl_cloud_and_shadow_dataset.csv'))\n",
    "\n",
    "google_automl_dataset = pd.read_csv( '/app/data_science/google_automl_cloud_and_shadow_dataset_small.csv')\n",
    "google_automl_dataset['image_prefix'] = google_automl_dataset['gcs_uri'].str.split('/').apply(lambda x: x[-1].replace(\".png\", \"\"))\n",
    "google_automl_dataset = google_automl_dataset.set_index('image_prefix', drop=False)\n",
    "\n",
    "train = df.loc[google_automl_dataset[google_automl_dataset['set'] == 'TRAIN'].index]\n",
    "valid = df.loc[google_automl_dataset[google_automl_dataset['set'] == 'VALIDATION'].index]\n",
    "test = df.loc[google_automl_dataset[google_automl_dataset['set'] == 'TEST'].index]\n",
    "\n",
    "print(len(train), len(valid), len(test))\n",
    "print(len(train) + len(valid) + len(test) == len(google_automl_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(root + '/cloud_and_shadow_stats.csv'):\n",
    "    all_stats = pd.read_csv(root + '/cloud_and_shadow_stats.csv')\n",
    "else:\n",
    "    stat_list = []\n",
    "    npy_image_dir = root + \"/npy_image_files\"\n",
    "    npy_files = [npy_image_dir + \"/\" + file + \".npy\" for file in train['image_prefix'].values]\n",
    "    start = time.time()\n",
    "    stats = stats_for_numpy_images(npy_files,  use_test_data=False)\n",
    "    stats['data'] = 'all'\n",
    "    stat_list.append(stats)\n",
    "    \n",
    "    # get stats per class\n",
    "    no_cloud = train[train['has_cloud_and_shadow'] == 0]\n",
    "    cloud = train[train['has_cloud_and_shadow'] == 1]\n",
    "    print(len(no_cloud), len(cloud))\n",
    "\n",
    "    for name, data in [('no_cloud', no_cloud), ('cloud', cloud)]:\n",
    "        npy_files = [npy_image_dir + \"/\" + file + \".npy\" for file in data['image_prefix'].values]\n",
    "        stats = stats_for_numpy_images(npy_files,  use_test_data=False)\n",
    "        stats['data'] = name\n",
    "        stat_list.append(stats)    \n",
    "    \n",
    "    all_stats = pd.concat(stat_list)\n",
    "    all_stats['band'] = all_stats.index\n",
    "    all_stats = all_stats.reset_index()  \n",
    "    all_stats = all_stats.drop('index', axis=1)    \n",
    "    all_stats.to_csv(root + '/cloud_and_shadow_stats.csv', index=False)\n",
    "        \n",
    "    print(f'stats computed in {time.time() - start}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = all_stats[all_stats['data'] == 'all']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_histories(histories):\n",
    "    full_history = defaultdict(list)\n",
    "\n",
    "    for history in histories:\n",
    "        for key, value in history.history.items():\n",
    "            full_history[key].extend(value)\n",
    "    return full_history\n",
    "\n",
    "\n",
    "def graph_model_history(history):\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    t = f.suptitle('Basic CNN Performance', fontsize=12)\n",
    "    f.subplots_adjust(top=0.85, wspace=0.3)\n",
    "\n",
    "    max_epoch = len(history['val_loss']) + 1\n",
    "    epoch_list = list(range(1, max_epoch))\n",
    "    ax1.plot(epoch_list, history['accuracy'], label='Train Accuracy')\n",
    "    ax1.plot(epoch_list, history['val_accuracy'], label='Validation Accuracy')\n",
    "    ax1.set_xticks(np.arange(1, max_epoch, 5))\n",
    "    ax1.set_ylabel('Accuracy Value')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_title('Accuracy')\n",
    "    l1 = ax1.legend(loc=\"best\")\n",
    "\n",
    "    ax2.plot(epoch_list, history['loss'], label='Train Loss')\n",
    "    ax2.plot(epoch_list, history['val_loss'], label='Validation Loss')\n",
    "    ax2.set_xticks(np.arange(1, max_epoch, 5))\n",
    "    ax2.set_ylabel('Loss Value')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_title('Loss')\n",
    "    l2 = ax2.legend(loc=\"best\")\n",
    "\n",
    "\n",
    "def predict(model, model_path, x, batch_size, n_classes):\n",
    "    thresholds = np.array([0.5 for _ in range(n_classes)])\n",
    "    model.load_weights(model_path)\n",
    "\n",
    "    predict_generator = AugmentedImageSequenceFromNpy(x=x, y=None, batch_size=batch_size,\n",
    "                                                        augmentations=AUGMENTATIONS_TEST)\n",
    "    # Generators\n",
    "    pred_test_probs = model.predict_generator(predict_generator)\n",
    "    pred_test_labels = pd.DataFrame(pred_test_probs, columns=classes)\n",
    "    pred_test_labels = pred_test_labels.apply(lambda x: x > thresholds, axis=1)\n",
    "    # Convert boolean predictions to labels\n",
    "    pred_test_lables = pred_test_labels.apply(lambda row: ' '.join(row[row].index), axis=1)\n",
    "\n",
    "    del predict_generator\n",
    "    gc.collect()\n",
    "\n",
    "    return pred_test_labels\n",
    "\n",
    "AUGMENTATIONS_TRAIN = Compose([\n",
    "    Flip(p=0.5),\n",
    "    Rotate(limit=(0, 360), p=0.5)\n",
    "])\n",
    "\n",
    "AUGMENTATIONS_TEST = Compose([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1907, 1) (1,)\n",
      "(1907, 1) (1,)\n"
     ]
    }
   ],
   "source": [
    "x_train = train['image_path'].values\n",
    "x_valid = valid['image_path'].values\n",
    "x_test = test['image_path'].values\n",
    "\n",
    "target = 'has_cloud_and_shadow_target'\n",
    "y_train = np.stack(train[target].values)\n",
    "y_valid = np.stack(valid[target].values)\n",
    "y_test = np.stack(test[target].values)\n",
    "\n",
    "print(y_train.shape, y_train[0].shape)\n",
    "\n",
    "if use_small_dataset:\n",
    "    size = batch_size\n",
    "    n_epochs = 3\n",
    "    x_train = np.concatenate([x_train[:size], x_train[-size:]])\n",
    "    x_valid = np.concatenate([x_valid[:size], x_valid[-size:]])\n",
    "    x_test = np.concatenate([x_test[:size], x_test[-size:]])\n",
    "\n",
    "    y_train = np.concatenate([y_train[:size], y_train[-size:]])\n",
    "    y_valid = np.concatenate([y_valid[:size], y_valid[-size:]])\n",
    "    y_test = np.concatenate([y_test[:size], y_test[-size:]])\n",
    "elif use_random_small_dataset:\n",
    "    shape = (100, 1)\n",
    "    x_train = np.concatenate([np.ones(shape), np.zeros(shape)])\n",
    "    y_train = np.concatenate([np.ones(shape), np.zeros(shape)])\n",
    "\n",
    "    x_valid = np.concatenate([np.ones(shape), np.zeros(shape)])\n",
    "    y_valid = np.concatenate([np.ones(shape), np.zeros(shape)])\n",
    "\n",
    "    y_train = np.random.randint(0, 2, (len(train), 44))\n",
    "    y_valid = np.random.randint(0, 2, (len(valid), 44))\n",
    "    y_test = np.random.randint(0, 2, (len(test), 44))\n",
    "    y_test_labels = test['labels'].values\n",
    "\n",
    "print(y_train.shape, y_train[0].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 43200) (43200,) (128,) ()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/app/env/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.546875\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# sanity check the generator output\n",
    "train_batch_generator = SklearnBatchGenerator(x_train, y_train, batch_size, augmentations=None, band_stats=stats)\n",
    "valid_batch_generator = SklearnBatchGenerator(x_valid, y_valid, batch_size, augmentations=None, band_stats=stats)\n",
    "\n",
    "train_batch_generator.on_epoch_end()\n",
    "valid_batch_generator.on_epoch_end()\n",
    "\n",
    "clf = LogisticRegression()\n",
    "x, y = train_batch_generator[0]\n",
    "print(x.shape, x[0].shape, y.shape, y[0].shape)\n",
    "assert x.shape[-1] == 120 * 120 * 3\n",
    "clf.fit(x, y)\n",
    "\n",
    "x, y = valid_batch_generator[0]\n",
    "pred = clf.predict(x)\n",
    "print(accuracy_score(pred, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.04255583572926459 0.8784629281732327\n",
      "-0.055612034546092 0.9152328872912798\n",
      "-0.10637636081662913 0.85306616746429\n",
      "0.05590347030378144 1.0581742231027134\n",
      "0.009320551740954142 1.008796793941446\n"
     ]
    }
   ],
   "source": [
    "# check that the pixel values are different and reasonable\n",
    "num_outputs = 0\n",
    "for batch_x, batch_y in train_batch_generator.make_one_shot_iterator():\n",
    "    print(batch_x.mean(), batch_x.std())\n",
    "    num_outputs += 1\n",
    "    if num_outputs > 4:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/jovyan/work/data/big_earth/npy_image_files/S2A_MSIL2A_20170613T101031_57_5.npy'\n",
      " '/home/jovyan/work/data/big_earth/npy_image_files/S2B_MSIL2A_20170914T93030_56_82.npy'\n",
      " '/home/jovyan/work/data/big_earth/npy_image_files/S2B_MSIL2A_20171016T101009_47_86.npy'\n",
      " '/home/jovyan/work/data/big_earth/npy_image_files/S2B_MSIL2A_20180417T102019_59_50.npy'\n",
      " '/home/jovyan/work/data/big_earth/npy_image_files/S2A_MSIL2A_20180225T114351_6_43.npy']\n",
      "\n",
      "\n",
      "\n",
      "['/home/jovyan/work/data/big_earth/npy_image_files/S2A_MSIL2A_20180205T100211_64_19.npy'\n",
      " '/home/jovyan/work/data/big_earth/npy_image_files/S2B_MSIL2A_20170924T93021_20_59.npy'\n",
      " '/home/jovyan/work/data/big_earth/npy_image_files/S2A_MSIL2A_20170701T093031_64_73.npy'\n",
      " '/home/jovyan/work/data/big_earth/npy_image_files/S2B_MSIL2A_20180511T100029_26_44.npy'\n",
      " '/home/jovyan/work/data/big_earth/npy_image_files/S2A_MSIL2A_20171101T094131_44_70.npy']\n"
     ]
    }
   ],
   "source": [
    "# make sure shuffle works\n",
    "print(train_batch_generator.x[:5])\n",
    "print('\\n\\n')\n",
    "train_batch_generator.on_epoch_end()\n",
    "print(train_batch_generator.x[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_num 1 - 10.3475 sec - 0.6403162055335968\n",
      "epoch_num 2 - 13.5856 sec - 0.6047430830039525\n",
      "epoch_num 3 - 14.3071 sec - 0.6482213438735178\n",
      "epoch_num 4 - 15.1620 sec - 0.5849802371541502\n",
      "epoch_num 5 - 12.0106 sec - 0.6482213438735178\n",
      "epoch_num 6 - 14.7846 sec - 0.4782608695652174\n",
      "epoch_num 7 - 14.2541 sec - 0.6086956521739131\n",
      "epoch_num 8 - 17.1796 sec - 0.6363636363636364\n",
      "epoch_num 9 - 15.3449 sec - 0.6086956521739131\n",
      "Ending training due to no improvement\n"
     ]
    }
   ],
   "source": [
    "import joblib \n",
    "\n",
    "history = list()\n",
    "\n",
    "classes = np.array([0, 1])\n",
    "epochs_without_improvement = 0\n",
    "\n",
    "now = datetime.datetime.utcnow().strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "experiment_name = f\"sgd_classifier_default_2020_1_31\"\n",
    "gcs_model_dir = \"model/models\"\n",
    "model_path = os.path.join(model_dir, experiment_name + \".joblib\")\n",
    "model_gcs_path = os.path.join(gcs_model_dir, experiment_name + \".joblib\")\n",
    "model_metadata_path = os.path.join(model_dir, experiment_name + \"_metadata.json\")\n",
    "model_metadata_gcs_path = os.path.join(gcs_model_dir, experiment_name + \"_metadata.json\")\n",
    "\n",
    "model, model_base_metadata = get_model_and_metadata_from_gcs(bucket, model_dir, \"joblib\", joblib.load, gcs_model_dir, \n",
    "                                                             experiment_name)\n",
    "\n",
    "if model is not None:\n",
    "    print('Resuming training at epoch', model_base_metadata['epoch'])\n",
    "else:\n",
    "    model = SGDClassifier()\n",
    "    model_base_metadata = {\n",
    "        'data': 'train_valid_google_automl_cloud_and_shadow_dataset_small.csv',\n",
    "        'data_prep': 'normalization_augmentation',\n",
    "        'experiment_name': experiment_name,\n",
    "        'experiment_start_time': now,\n",
    "        'model': SGDClassifier.__name__,\n",
    "        'random_state': random_seed,\n",
    "        'epoch': 0\n",
    "    }\n",
    "        \n",
    "# Shuffle the data\n",
    "train_batch_generator.on_epoch_end()\n",
    "valid_batch_generator.on_epoch_end()\n",
    "train_start = time.time()\n",
    "best_model = None\n",
    "max_accuracy_valid = None\n",
    "for epoch in range(int(model_base_metadata['epoch']) + 1, n_epochs):\n",
    "    start = time.time()\n",
    "    for batch_x, batch_y in train_batch_generator.make_one_shot_iterator():\n",
    "        model.partial_fit(batch_x, batch_y, classes=classes)\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print(\"training completed in\", time.time() - start, \"seconds\")\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    actual_y_train, pred_y_train = train_batch_generator.get_predictions(model)\n",
    "    actual_y_valid, pred_y_valid = valid_batch_generator.get_predictions(model)\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print(\"prediction completed in\", time.time() - start, \"seconds\")\n",
    "\n",
    "    epoch_time = f\"{time.time() - start:.4f}\"\n",
    "    epoch_metrics = {\n",
    "        'accuracy_train': sklearn.metrics.accuracy_score(actual_y_train, pred_y_train),\n",
    "        'accuracy_valid': sklearn.metrics.accuracy_score(actual_y_valid, pred_y_valid),        \n",
    "        \"f1_score_train\": sklearn.metrics.f1_score(actual_y_train, pred_y_train),\n",
    "        \"f1_score_valid\": sklearn.metrics.f1_score(actual_y_valid, pred_y_valid),        \n",
    "    }\n",
    "    history.append(epoch_metrics)\n",
    "    \n",
    "    print(\"epoch_num\", epoch, \"-\", epoch_time, \"sec -\", epoch_metrics['accuracy_valid'])\n",
    "    \n",
    "    if max_accuracy_valid is None or epoch_metrics['accuracy_valid'] > max_accuracy_valid:\n",
    "        max_accuracy_valid = epoch_metrics['accuracy_valid']\n",
    "        dump(model, model_path)\n",
    "        with open(model_metadata_path, 'w+') as json_file:\n",
    "            model_base_metadata.update({\n",
    "                'epoch': str(epoch),\n",
    "                'confusion_matrix': numpy_to_json(confusion_matrix(actual_y_valid, pred_y_valid)),\n",
    "                'precision_recall_curve': sklearn_precision_recall_curve_to_dict(\n",
    "                    sklearn.metrics.precision_recall_curve(actual_y_valid, pred_y_valid)),\n",
    "                'history': history,\n",
    "                'train_time_elapsed': time.time() - train_start\n",
    "            })\n",
    "            json.dump(model_base_metadata, json_file)\n",
    "        \n",
    "        for filename, gcs_filename in [(model_path, model_gcs_path), (model_metadata_path, model_metadata_gcs_path)]:\n",
    "            blob = bucket.blob(gcs_filename)\n",
    "            blob.upload_from_filename(filename)\n",
    "            \n",
    "        epochs_without_improvement = 0\n",
    "    else:\n",
    "        epochs_without_improvement += 1\n",
    "        \n",
    "    if epochs_without_improvement == early_stopping_patience:\n",
    "        print(\"Ending training due to no improvement\")\n",
    "        break\n",
    "        \n",
    "    train_batch_generator.on_epoch_end()\n",
    "    valid_batch_generator.on_epoch_end()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'/home/jovyan/work/data/big_earth/npy_image_files/S2A_MSIL2A_20170701T093031_83_63.npy', shape=(), dtype=string) tf.Tensor([1], shape=(1,), dtype=uint8)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def gen(x,  y):\n",
    "    for x, y in zip(x, y):\n",
    "        yield (x, y)\n",
    "        \n",
    "dataset = tf.data.Dataset.from_generator(gen, \n",
    "                             output_types=(tf.string, tf.uint8),\n",
    "                             args=(x_train, y_train,)).shuffle(buffer_size=len(x_train)) \n",
    "\n",
    "for x, y in dataset.make_one_shot_iterator():\n",
    "    print(x, y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x Tensor(\"args_0:0\", dtype=string)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "in converted code:\n\n    <ipython-input-467-34bf084b9ba9>:17 image_loader  *\n        img = np.load(image_path[0])\n    /app/env/lib/python3.6/site-packages/numpy/lib/npyio.py:428 load\n        fid = open(os_fspath(file), \"rb\")\n\n    TypeError: expected str, bytes or os.PathLike object, not Tensor\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-468-34bf084b9ba9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactual_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_y_prob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_image_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maugmentations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mband_stats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;31m# train_generator = AugmentedImageSequenceFromNpy(x=x_train, y=y_train, batch_size=batch_size,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-468-34bf084b9ba9>\u001b[0m in \u001b[0;36mget_image_dataset\u001b[0;34m(x, y, augmentations, band_stats, batch_size)\u001b[0m\n\u001b[1;32m     33\u001b[0m                                  \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m                                  args=(x, y,)).shuffle(buffer_size=len(x))\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_parallel_calls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprefetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/app/env/lib/python3.6/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, map_func, num_parallel_calls)\u001b[0m\n\u001b[1;32m   1902\u001b[0m       return DatasetV1Adapter(\n\u001b[1;32m   1903\u001b[0m           ParallelMapDataset(\n\u001b[0;32m-> 1904\u001b[0;31m               self, map_func, num_parallel_calls, preserve_cardinality=False))\n\u001b[0m\u001b[1;32m   1905\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1906\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mdeprecation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeprecated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Use `tf.data.Dataset.map()\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/app/env/lib/python3.6/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dataset, map_func, num_parallel_calls, use_inter_op_parallelism, preserve_cardinality, use_legacy_function)\u001b[0m\n\u001b[1;32m   3452\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transformation_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3453\u001b[0m         \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3454\u001b[0;31m         use_legacy_function=use_legacy_function)\n\u001b[0m\u001b[1;32m   3455\u001b[0m     self._num_parallel_calls = ops.convert_to_tensor(\n\u001b[1;32m   3456\u001b[0m         num_parallel_calls, dtype=dtypes.int32, name=\"num_parallel_calls\")\n",
      "\u001b[0;32m/app/env/lib/python3.6/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m   2693\u001b[0m       \u001b[0mresource_tracker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtracking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResourceTracker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2694\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtracking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresource_tracker_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_tracker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2695\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_concrete_function_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2696\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0madd_to_graph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2697\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/app/env/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1852\u001b[0m     \u001b[0;34m\"\"\"Bypasses error checking when getting a graph function.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m     graph_function = self._get_concrete_function_internal_garbage_collected(\n\u001b[0;32m-> 1854\u001b[0;31m         *args, **kwargs)\n\u001b[0m\u001b[1;32m   1855\u001b[0m     \u001b[0;31m# We're returning this concrete function to someone, and they may keep a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1856\u001b[0m     \u001b[0;31m# reference to the FuncGraph without keeping a reference to the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/app/env/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1846\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_signature\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1849\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/app/env/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2148\u001b[0m         \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2149\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgraph_function\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2150\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2151\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2152\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/app/env/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   2039\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2040\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2041\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   2042\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2043\u001b[0m         \u001b[0;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/app/env/lib/python3.6/site-packages/tensorflow_core/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    913\u001b[0m                                           converted_func)\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/app/env/lib/python3.6/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mwrapper_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   2687\u001b[0m           attributes=defun_kwargs)\n\u001b[1;32m   2688\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=missing-docstring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2689\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_wrapper_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2690\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2691\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/app/env/lib/python3.6/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m_wrapper_helper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   2632\u001b[0m         \u001b[0mnested_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2634\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2635\u001b[0m       \u001b[0;31m# If `func` returns a list of tensors, `nest.flatten()` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2636\u001b[0m       \u001b[0;31m# `ops.convert_to_tensor()` would conspire to attempt to stack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/app/env/lib/python3.6/site-packages/tensorflow_core/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    235\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m           \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: in converted code:\n\n    <ipython-input-467-34bf084b9ba9>:17 image_loader  *\n        img = np.load(image_path[0])\n    /app/env/lib/python3.6/site-packages/numpy/lib/npyio.py:428 load\n        fid = open(os_fspath(file), \"rb\")\n\n    TypeError: expected str, bytes or os.PathLike object, not Tensor\n"
     ]
    }
   ],
   "source": [
    "#             img = tf.constant(augmentations(normalized_img), dtype=tf.float64, shape=(120, 120, 3))\n",
    "def get_image_dataset(x, y, augmentations, band_stats, batch_size):\n",
    "        \n",
    "    def image_path_and_label(image_paths, labels):\n",
    "        for idx, image_path in enumerate(image_paths):\n",
    "            # Have to return tensors\n",
    "            yield [image_path], labels[idx]\n",
    "\n",
    "    means = band_stats['mean'].values\n",
    "    stds = band_stats['std'].values\n",
    "    \n",
    "    def image_loader(image_path, label):\n",
    "        print(image_path)\n",
    "        img = np.load(image_path[0])\n",
    "        normalized_img = (img - means) / stds\n",
    "#         label = tf.constant(label, dtype=tf.uint8, shape=(1,))\n",
    "        \n",
    "        if augmentations is not None:\n",
    "\n",
    "            return augmentations(normalized_img), label \n",
    "        else:\n",
    "#             img = tf.constant(normalized_img, dtype=tf.float64, shape=(120, 120, 3))\n",
    "            return normalized_img, label \n",
    "\n",
    "#     def tf_image_loader(image_path, label):\n",
    "#       return tf.py_function(func = image_loader,\n",
    "#                     inp = (image_path, label),\n",
    "#                     Tout = (tf.float64,    # (H,W,3) img\n",
    "#                             tf.uint8))  # label\n",
    "\n",
    "\n",
    "    dataset = tf.data.Dataset.from_generator(image_path_and_label, \n",
    "                                 output_types=(tf.string, tf.uint8),\n",
    "                                 output_shapes=((1,), (1,)),      \n",
    "                                 args=(x, y,)).shuffle(buffer_size=len(x))\n",
    "    dataset = dataset.map(image_loader, num_parallel_calls=8)\n",
    "\n",
    "    return dataset.prefetch(5).batch(batch_size)\n",
    "\n",
    "def get_predictions_for_dataset(dataset, model, threshold=.5):\n",
    "    pred_y_batches = []\n",
    "    actual_y_batches = []\n",
    "    for batch_x, batch_y in dataset.make_one_shot_iterator():\n",
    "        pred_y_batches.append(model.predict(batch_x))\n",
    "        actual_y_batches.append(batch_y)\n",
    "\n",
    "    pred_y_prob = []\n",
    "    pred_y = []\n",
    "    for pred_y_batch in pred_y_batches:\n",
    "        for pred in pred_y_batch:\n",
    "            pred_y_prob.append(pred)\n",
    "            pred = 0 if pred < threshold else 1\n",
    "            pred_y.append(pred)\n",
    "\n",
    "    actual_y = []\n",
    "    for actual_y_batch in actual_y_batches:\n",
    "        for actual in actual_y_batch:\n",
    "            actual_y.append(actual)\n",
    "\n",
    "    return np.array(actual_y), np.array(pred_y), np.array(pred_y_prob)\n",
    "\n",
    "train_dataset = get_image_dataset(x_train, y_train, augmentations=None, band_stats=stats, batch_size=128)\n",
    "\n",
    "# train_generator = AugmentedImageSequenceFromNpy(x=x_train, y=y_train, batch_size=batch_size,\n",
    "#                                                 augmentations=None, band_stats=stats)\n",
    "\n",
    "# imgs, labels = train_generator[0]\n",
    "# print(imgs.shape, imgs[0][0][0], labels.shape, labels[0])\n",
    "\n",
    "# num_outputs = 0\n",
    "# for batch_x, batch_y in train_generator.make_one_shot_iterator():\n",
    "#     print(batch_x.mean(), batch_x.std(), batch_x.min(), batch_x.max())\n",
    "#     num_outputs += 1\n",
    "#     if num_outputs > 4:\n",
    "#         break\n",
    "\n",
    "num_outputs = 0\n",
    "train_iter = train_dataset.make_one_shot_iterator()\n",
    "imgs, labels = train_iter.get_next()\n",
    "print(imgs.shape, imgs.numpy()[0][0][0], labels.shape, labels.numpy()[0])\n",
    "\n",
    "for batch_x, batch_y in train_dataset.make_one_shot_iterator():\n",
    "    batch_x = batch_x.numpy() \n",
    "    print(batch_x.mean(), batch_x.std(), batch_x.min(), batch_x.max())\n",
    "    num_outputs += 1\n",
    "    if num_outputs > 4:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorSpec(shape=<unknown>, dtype=tf.float64, name=None),\n",
       " TensorSpec(shape=<unknown>, dtype=tf.uint8, name=None))"
      ]
     },
     "execution_count": 447,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AugmentedImageSequenceFromNpy finished 15 batches with 1907 elements in 11.631208896636963\n",
      "Image dataset finished 15 batches with 1907 elements in 6.682146310806274\n"
     ]
    }
   ],
   "source": [
    "train_generator = AugmentedImageSequenceFromNpy(x=x_train, y=y_train, batch_size=batch_size,\n",
    "                                                augmentations=None, band_stats=stats)\n",
    "\n",
    "start = time.time()\n",
    "num_batches = 0\n",
    "num_els = 0\n",
    "for x, y in train_generator.make_one_shot_iterator():\n",
    "    num_batches += 1\n",
    "    num_els += len(x)\n",
    "    continue\n",
    "print(f'AugmentedImageSequenceFromNpy finished {num_batches} batches with {num_els} elements in {time.time() - start}')\n",
    "\n",
    "start = time.time()\n",
    "num_batches = 0\n",
    "num_els = 0\n",
    "train_dataset = get_image_dataset(x_train, y_train, augmentations=None, band_stats=stats, batch_size=batch_size)\n",
    "for x, y in train_dataset.make_one_shot_iterator():\n",
    "    num_batches += 1\n",
    "    num_els += len(x)    \n",
    "    continue\n",
    "print(f'Image dataset finished {num_batches} batches with {num_els} elements in {time.time() - start}')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary_crossentropy - random numbers 0.9990679927848966\n",
      "binary_crossentropy - cnn with initial weights - actual data 0.97949386\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7f5d8faa7780>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "model = basic_cnn_model((120, 120, 3), n_classes)\n",
    "y_actual, y_pred, y_pred_probs = get_predictions_for_dataset(train_batch_generator, model)\n",
    "\n",
    "print('binary_crossentropy - random numbers', \n",
    "      binary_crossentropy(np.random.randint(2, size=128), np.random.random_sample(128)).numpy())\n",
    "print('binary_crossentropy - cnn with initial weights - actual data', \n",
    "      binary_crossentropy(np.ravel(y_actual), np.ravel(y_pred_probs)).numpy())\n",
    "\n",
    "pd.DataFrame(y_pred_probs).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "ValueError: `generator` yielded an element of shape (1, 120, 120, 3) where an element of shape (1,) was expected.\nTraceback (most recent call last):\n\n  File \"/app/env/lib/python3.6/site-packages/tensorflow_core/python/ops/script_ops.py\", line 221, in __call__\n    ret = func(*args)\n\n  File \"/app/env/lib/python3.6/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\", line 621, in generator_py_func\n    \"of shape %s was expected.\" % (ret_array.shape, expected_shape))\n\nValueError: `generator` yielded an element of shape (1, 120, 120, 3) where an element of shape (1,) was expected.\n\n\n\t [[{{node PyFunc}}]] [Op:IteratorGetNextSync]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-439-23b81e9c2e5c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m                                           batch_size=batch_size)\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_batch_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_one_shot_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/app/env/lib/python3.6/site-packages/tensorflow_core/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    620\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# For Python 3 compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 622\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    623\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/app/env/lib/python3.6/site-packages/tensorflow_core/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    664\u001b[0m     \u001b[0;34m\"\"\"Returns a nested structure of `Tensor`s containing the next element.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 666\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    667\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/app/env/lib/python3.6/site-packages/tensorflow_core/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    649\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m             \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m             output_shapes=self._flat_output_shapes)\n\u001b[0m\u001b[1;32m    652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/app/env/lib/python3.6/site-packages/tensorflow_core/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36miterator_get_next_sync\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   2671\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2672\u001b[0m         \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2673\u001b[0;31m       \u001b[0m_six\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2674\u001b[0m   \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2675\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/app/env/lib/python3.6/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: ValueError: `generator` yielded an element of shape (1, 120, 120, 3) where an element of shape (1,) was expected.\nTraceback (most recent call last):\n\n  File \"/app/env/lib/python3.6/site-packages/tensorflow_core/python/ops/script_ops.py\", line 221, in __call__\n    ret = func(*args)\n\n  File \"/app/env/lib/python3.6/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\", line 621, in generator_py_func\n    \"of shape %s was expected.\" % (ret_array.shape, expected_shape))\n\nValueError: `generator` yielded an element of shape (1, 120, 120, 3) where an element of shape (1,) was expected.\n\n\n\t [[{{node PyFunc}}]] [Op:IteratorGetNextSync]"
     ]
    }
   ],
   "source": [
    "train_batch_generator = get_image_dataset(x, y, augmentations=None, band_stats=stats, \n",
    "                                          batch_size=batch_size)\n",
    "\n",
    "for x, y in train_batch_generator.make_one_shot_iterator():\n",
    "    print(x.shape, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 0s 313ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 346ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 326ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 280ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 337ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 00007: early stopping\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-437-5d0a62c23a42>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# train_generator = AugmentedImageSequenceFromNpy(x=x_train[:10], y=y_train[:10], batch_size=batch_size,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m#                                                 augmentations=None, band_stats=stats)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mvalidate_can_overfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_batch_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-437-5d0a62c23a42>\u001b[0m in \u001b[0;36mvalidate_can_overfit\u001b[0;34m(model, train_generator)\u001b[0m\n\u001b[1;32m     15\u001b[0m                         shuffle=True, verbose=1)\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m1e-14\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Confirm that the model can overfit on a subset of the data\n",
    "def validate_can_overfit(model, train_generator):\n",
    "    n_epochs = 100\n",
    "    metrics = [Accuracy()]\n",
    "    loss = 'binary_crossentropy'\n",
    "    metric_to_monitor = 'accuracy'\n",
    "    callbacks = [EarlyStopping(monitor=metric_to_monitor, patience=early_stopping_patience, verbose=1)]\n",
    "\n",
    "    optimizer = Adam(lr=3e-4)\n",
    "    model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
    "\n",
    "    history = model.fit_generator(train_generator,\n",
    "                        epochs=n_epochs,\n",
    "                        callbacks=callbacks,\n",
    "                        shuffle=True, verbose=1)\n",
    "\n",
    "    assert history.history['loss'][-1] <= 1e-14\n",
    "    assert history.history['accuracy'][-1] == 1\n",
    "\n",
    "\n",
    "# Include both positive and negative class    \n",
    "x = np.concatenate([x_train[:5], x_train[-5:]])\n",
    "y = np.concatenate([y_train[:5], y_train[-5:]])\n",
    "train_batch_generator = get_image_dataset(x, y, augmentations=None, band_stats=stats, \n",
    "                                          batch_size=batch_size)\n",
    "\n",
    "# train_generator = AugmentedImageSequenceFromNpy(x=x_train[:10], y=y_train[:10], batch_size=batch_size, \n",
    "#                                                 augmentations=None, band_stats=stats)\n",
    "validate_can_overfit(model, train_batch_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def train_keras_model(*, bucket, model_dir, gcs_model_dir, gcs_log_dir, experiment_name, start_model,\n",
    "                     n_epochs=100):\n",
    "    model, model_base_metadata = get_model_and_metadata_from_gcs(bucket, model_dir, \"h5\", load_model, gcs_model_dir, experiment_name)\n",
    "\n",
    "    model_and_metadata_filepath = os.path.join(model_dir, experiment_name)\n",
    "    gcs_model_and_metadata_filepath = os.path.join(gcs_model_dir, experiment_name)\n",
    "    gcs_log_dir = os.path.join(gcs_log_dir, experiment_name)\n",
    "\n",
    "    if model is not None:\n",
    "        print('Resuming training at epoch', int(model_base_metadata['epoch']) + 1)\n",
    "    else:\n",
    "        now = datetime.datetime.utcnow().strftime(\"%Y-%m-%d %H:%M\")\n",
    "        model = start_model\n",
    "        model_base_metadata = {\n",
    "            'data': 'train_valid_google_automl_cloud_and_shadow_dataset_small.csv',\n",
    "            'data_prep': 'normalization_augmentation',\n",
    "            'experiment_name': experiment_name,\n",
    "            'experiment_start_time': now,\n",
    "            'model': 'keras_cnn',\n",
    "            'random_state': random_seed,\n",
    "            # so that initial_epoch is 0\n",
    "            'epoch': -1\n",
    "        }        \n",
    "\n",
    "    print(f'len(train): {len(x_train)}')\n",
    "    print(f'len(valid): {len(x_valid)}')\n",
    "\n",
    "    histories = []\n",
    "    metrics = ['accuracy']\n",
    "    loss = 'binary_crossentropy'\n",
    "    metric_to_monitor = 'val_accuracy'\n",
    "\n",
    "    optimizer = Adam()\n",
    "    model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
    "\n",
    "    verbosity = 0\n",
    "    # Generators\n",
    "    train_generator = AugmentedImageSequenceFromNpy(x=x_train, y=y_train, batch_size=batch_size,\n",
    "                                                    augmentations=None, band_stats=stats)\n",
    "\n",
    "    valid_generator = AugmentedImageSequenceFromNpy(x=x_valid, y=y_valid, batch_size=batch_size,\n",
    "                                                    augmentations=None, band_stats=stats)\n",
    "\n",
    "    callbacks = [\n",
    "#         EarlyStopping(monitor=metric_to_monitor, patience=early_stopping_patience, verbose=verbosity),\n",
    "#         ReduceLROnPlateau(monitor=metric_to_monitor, factor=0.5, patience=early_stopping_patience, min_lr=1e-6),\n",
    "        TensorBoard(gcs_log_dir, histogram_freq=1),\n",
    "        ModelCheckpointGCS(filepath=model_and_metadata_filepath, gcs_filepath=gcs_model_and_metadata_filepath, \n",
    "                           gcs_bucket=bucket, model_metadata=model_base_metadata, monitor=metric_to_monitor, \n",
    "                           verbose=verbosity)\n",
    "    ]\n",
    "\n",
    "    history = model.fit(train_generator, initial_epoch=int(model_base_metadata['epoch']) + 1,\n",
    "                                  epochs=n_epochs,\n",
    "                                  steps_per_epoch=len(train_generator),\n",
    "                                  callbacks=callbacks,\n",
    "                                  validation_data=valid_generator, validation_steps=len(valid_generator),\n",
    "                                  shuffle=True, verbose=1)\n",
    "\n",
    "    actual_y_train, pred_y_train, pred_y_train_probs = train_generator.get_predictions(model)\n",
    "    actual_y_valid, pred_y_valid, pred_y_valid_probs = valid_generator.get_predictions(model)\n",
    "\n",
    "    metadata_filepath = f\"{model_and_metadata_filepath}_metadata.json\"\n",
    "    with open(metadata_filepath, 'r') as json_file:\n",
    "        best_model_metadata = json.load(json_file)\n",
    "\n",
    "    best_model_metadata.update({\n",
    "        'accuracy_train': sklearn.metrics.accuracy_score(actual_y_train, pred_y_train),\n",
    "        'accuracy_valid': sklearn.metrics.accuracy_score(actual_y_valid, pred_y_valid),\n",
    "        'f1_score_train': sklearn.metrics.f1_score(actual_y_train, pred_y_train),\n",
    "        'f1_score_valid': sklearn.metrics.f1_score(actual_y_valid, pred_y_valid),\n",
    "        'confusion_matrix': numpy_to_json(sklearn.metrics.confusion_matrix(actual_y_valid, pred_y_valid)),\n",
    "        'precision_recall_curve': sklearn_precision_recall_curve_to_dict(\n",
    "            sklearn.metrics.precision_recall_curve(actual_y_valid, pred_y_valid)),\n",
    "    })\n",
    "\n",
    "    with open(metadata_filepath, 'w+') as json_file:\n",
    "        json.dump(best_model_metadata, json_file)\n",
    "\n",
    "    blob = bucket.blob(f\"{gcs_model_and_metadata_filepath}_metadata.json\")\n",
    "    blob.upload_from_filename(metadata_filepath)\n",
    "\n",
    "    # Attempt to avoid memory leaks\n",
    "    del train_generator\n",
    "    del valid_generator\n",
    "    gc.collect()\n",
    "    return history\n",
    "\n",
    "# if os.environ.get(\"SHOULD_PREDICT\", \"True\") == \"True\":\n",
    "#     pred_test_labels = predict(model=model, weight_dir=model_path, x=x_test, batch_size=batch_size, n_classes=n_classes)\n",
    "#     clf_report = classification_report(y_test_labels, pred_test_labels, target_names=classes)\n",
    "#     print(clf_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(train): 256\n",
      "len(valid): 256\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n",
      "Train for 2 steps, validate for 2 steps\n",
      "Epoch 1/3\n",
      "1/2 [==============>...............] - ETA: 4s - loss: 0.4389 - accuracy: 1.0000WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (2.222144). Check your callbacks.\n",
      "2/2 [==============================] - 30s 15s/step - loss: 47.7670 - accuracy: 0.5000 - val_loss: 7.8142 - val_accuracy: 0.5469\n",
      "Epoch 2/3\n",
      "2/2 [==============================] - 10s 5s/step - loss: 10.6520 - accuracy: 0.0469 - val_loss: 0.6800 - val_accuracy: 0.5469\n",
      "Epoch 3/3\n",
      "2/2 [==============================] - 11s 6s/step - loss: 0.7885 - accuracy: 0.5000 - val_loss: 0.6864 - val_accuracy: 0.5469\n",
      "Finished training for experiment cloud_and_shadow_basic_cnn_2020_1_31\n"
     ]
    }
   ],
   "source": [
    "experiment_name = f\"{project_name}_basic_cnn_2020_1_31\"\n",
    "history = train_keras_model(bucket=bucket, model_dir=model_dir, gcs_model_dir=gcs_model_dir, gcs_log_dir=gcs_log_dir, \n",
    "                  experiment_name=experiment_name, start_model=basic_cnn_model((120, 120, 3), n_classes=n_classes),\n",
    "                            n_epochs=3)\n",
    "logger.info(f\"Finished training for experiment {experiment_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f5e0485a828>"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading previously trained model.\n",
      "Resuming training at epoch 1\n",
      "len(train): 100\n",
      "len(valid): 100\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 1 steps, validate for 1 steps\n",
      "Epoch 2/3\n",
      "1/1 [==============================] - 20s 20s/step - loss: 1.4209 - accuracy: 0.0400 - val_loss: 5.7233 - val_accuracy: 0.0100\n",
      "Epoch 3/3\n",
      "WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (3.772809). Check your callbacks.\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.6108 - accuracy: 0.0300 - val_loss: 8.5210 - val_accuracy: 0.0000e+00\n",
      "Finished training for experiment cloud_and_shadow_basic_cnn_best_practices_2020_1_31\n",
      "Finished training for experiment cloud_and_shadow_basic_cnn_best_practices_2020_1_31\n"
     ]
    }
   ],
   "source": [
    "# experiment_name = f\"{project_name}_basic_cnn_best_practices_2020_1_31\"\n",
    "# train_keras_model(bucket=bucket, model_dir=model_dir, gcs_model_dir=gcs_model_dir, gcs_log_dir=gcs_log_dir, \n",
    "#                   experiment_name=experiment_name, start_model=basic_cnn_model_with_best_practices((120, 120, 3), n_classes=n_classes))\n",
    "# logger.info(f\"Finished training for experiment {experiment_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import classification_report\n",
    "\n",
    "# test_generator = AugmentedImageSequenceFromNpy(x=x_test, y=None, batch_size=batch_size,\n",
    "#                                                         augmentations=AUGMENTATIONS_TEST)\n",
    "# y_pred = model.predict(test_generator)\n",
    "# y_pred_binary = [0 if pred < .5 else 1 for pred in y_pred]\n",
    "# clf = classification_report(y_test, y_pred_binary,  target_names=['has_clouds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(pd.DataFrame(y_pred)[0].unique())\n",
    "# print(pd.DataFrame(y_pred_binary)[0].unique())\n",
    "# pd.DataFrame(y_pred)[0].unique()\n",
    "# pd.DataFrame(y_pred_binary)[0].unique()\n",
    "# full_histories = join_histories(histories)\n",
    "# graph_model_history(full_histories)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
